{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80c9fc2c-6e12-456a-9278-5119d2dd8792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# docker run --gpus all -it -v $(realpath ~/):/tf/All -v /home/rob/Data2:/home/rob/Data2 --env HF_DATASETS_CACHE=/home/rob/Data2/huggingface/datasets --env TRANSFORMERS_CACHE=/home/rob/Data2/huggingface/transformers -p 8888:8888 -p 6006:6006 d139afc9cfb2\n",
    "\n",
    "# This notebook relies on the output from previous notebooks, and reads from the folders ...\n",
    "# cbow_embeddings\n",
    "# glove_embeddings\n",
    "# skipgram_embeddings\n",
    "# elmo_embeddings\n",
    "\n",
    "\n",
    "# 2nd pass ... \n",
    "# Run Date: Thursday, January 19, 2023\n",
    "# Run Time: 00:00:16\n",
    "\n",
    "# First Run ...\n",
    "# Run Date: Thursday, January 19, 2023\n",
    "# Run Time: 00:00:15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7e67323-de11-4d92-9c6b-411b1d177327",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import date\n",
    "\n",
    "startTime = time.time()\n",
    "todaysDate = date.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd2f26d9-0e26-426d-a49d-f7ac572a2966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only target the 2070 Super ...\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80799580",
   "metadata": {},
   "source": [
    "## Classifying documents with embeddings\n",
    "\n",
    "<table align=\"left\">\n",
    "    <td>\n",
    "        <a target=\"_blank\" href=\"https://colab.research.google.com/github/thushv89/packt_nlp_tensorflow_2/blob/master/Ch04-Advance-Word-Vectors/ch4_document_classification.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "    </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66cf2460",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-19 17:15:03.560507: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-19 17:15:04.117935: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-01-19 17:15:04.117983: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-01-19 17:15:04.117990: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "%matplotlib inline\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from matplotlib import pylab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975ea2c9",
   "metadata": {},
   "source": [
    "## Downloading the data\n",
    "\n",
    "This code downloads a [BBC dataset](hhttp://mlg.ucd.ie/files/datasets/bbc-fulltext.zip) consisting of news articles published by BBC. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a066561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists\n",
      "bbc-fulltext.zip has already been extracted\n"
     ]
    }
   ],
   "source": [
    "url = 'http://mlg.ucd.ie/files/datasets/bbc-fulltext.zip'\n",
    "\n",
    "\n",
    "def download_data(url, data_dir):\n",
    "    \"\"\"Download a file if not present, and make sure it's the right size.\"\"\"\n",
    "    \n",
    "    # Create the data directory if not exist\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "    file_path = os.path.join(data_dir, 'bbc-fulltext.zip')\n",
    "    \n",
    "    # If file doesnt exist, download\n",
    "    if not os.path.exists(file_path):\n",
    "        print('Downloading file...')\n",
    "        filename, _ = urlretrieve(url, file_path)\n",
    "    else:\n",
    "        print(\"File already exists\")\n",
    "  \n",
    "    extract_path = os.path.join(data_dir, 'bbc')\n",
    "    \n",
    "    # If data has not been extracted already, extract data\n",
    "    if not os.path.exists(extract_path):        \n",
    "        with zipfile.ZipFile(os.path.join(data_dir, 'bbc-fulltext.zip'), 'r') as zipf:\n",
    "            zipf.extractall(data_dir)\n",
    "    else:\n",
    "        print(\"bbc-fulltext.zip has already been extracted\")\n",
    "    \n",
    "download_data(url, 'data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0544e94b",
   "metadata": {},
   "source": [
    "### Read Data\n",
    "\n",
    "Here we read all the files and keep them as a list of strings, where each string is a single article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc7494c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading files\n",
      "................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................. 300.txt\n",
      "Detected 2225 stories\n",
      "865163 words found in the total news set\n",
      "Example words (start):  Gadgets galore on show at fair  The 2005 Consumer \n",
      "Example words (end):   - the Warrior Poet opens in the UK on 21 January.\n"
     ]
    }
   ],
   "source": [
    "def read_data(data_dir):\n",
    "    \n",
    "    # This will contain the full list of stories\n",
    "    news_stories = []    \n",
    "    filenames = []\n",
    "    print(\"Reading files\")\n",
    "    \n",
    "    i = 0 # Just used for printing progress\n",
    "    for root, dirs, files in os.walk(data_dir):\n",
    "        \n",
    "        for fi, f in enumerate(files):\n",
    "            \n",
    "            # We don't read the readme file\n",
    "            if 'readme' in f.lower():\n",
    "                continue\n",
    "            \n",
    "            # Printing progress\n",
    "            i += 1\n",
    "            print(\".\"*i, f, end='\\r')\n",
    "            \n",
    "            # Open the file\n",
    "            with open(os.path.join(root, f), encoding='latin-1') as text_file:\n",
    "                \n",
    "                story = []\n",
    "                # Read all the lines\n",
    "                for row in text_file:\n",
    "                                        \n",
    "                    story.append(row.strip())\n",
    "                    \n",
    "                # Create a single string with all the rows in the doc\n",
    "                story = ' '.join(story)                        \n",
    "                # Add that to the list\n",
    "                news_stories.append(story)  \n",
    "                filenames.append(os.path.join(root, f))\n",
    "                \n",
    "        print('', end='\\r')\n",
    "        \n",
    "    print(f\"\\nDetected {len(news_stories)} stories\")\n",
    "    return news_stories, filenames\n",
    "                \n",
    "  \n",
    "news_stories, filenames = read_data(os.path.join('data', 'bbc'))\n",
    "\n",
    "# Printing some stats and sample data\n",
    "print(f\"{sum([len(story.split(' ')) for story in news_stories])} words found in the total news set\")\n",
    "print('Example words (start): ',news_stories[0][:50])\n",
    "print('Example words (end): ',news_stories[-1][-50:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12298545",
   "metadata": {},
   "source": [
    "## Build a Tokenizer\n",
    "\n",
    "Here we build a tokenizer, that performs simple preprocessing like,\n",
    "\n",
    "* Converting letters to lower case\n",
    "* Removing punctuation\n",
    "\n",
    "and tokenize the strings based on a defined separator. Then each token is converted to an Integer ID, as computers understand numbers, not strings. In the background, the tokenizer builds a word to index dictionary, that defines a unique ID for each word in the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3405d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data fitted on the tokenizer\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "n_vocab = 15000 + 1\n",
    "tokenizer = Tokenizer(\n",
    "    num_words=n_vocab - 1,\n",
    "    filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "    lower=True, split=' ', oov_token=''\n",
    ")\n",
    "\n",
    "tokenizer.fit_on_texts(news_stories)\n",
    "print(\"Data fitted on the tokenizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6cc22a",
   "metadata": {},
   "source": [
    "## Generate labels for data\n",
    "\n",
    "We generate a label using the filenames to train a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43c25400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data/bbc/tech/174.txt    4\n",
       "data/bbc/tech/170.txt    4\n",
       "data/bbc/tech/302.txt    4\n",
       "data/bbc/tech/256.txt    4\n",
       "data/bbc/tech/211.txt    4\n",
       "Name: 2, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_ser = pd.Series(filenames, index=filenames).str.split(os.path.sep, expand=True).iloc[:, -2].map(\n",
    "    {'business': 0, 'entertainment': 1, 'politics': 2, 'sport': 3, 'tech': 4}\n",
    ")\n",
    "labels_ser.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edec0dcc",
   "metadata": {},
   "source": [
    "## Create train/test split\n",
    "\n",
    "Here we use 67% data as training and 33% as testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1876e67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_labels, test_labels = train_test_split(labels_ser, test_size=0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e457b5d1",
   "metadata": {},
   "source": [
    "## Generating document embeddings\n",
    "\n",
    "Here we write a function to generate document embeddings from the previous embedding arrays we saved to the disk for `skip-gram`, `CBOW` and `GloVe` algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c0967e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_document_embeddings(texts, filenames, tokenizer, embeddings):\n",
    "    \n",
    "    \"\"\" This function takes a sequence of tokens and compute the mean embedding vector \\\n",
    "    from the word vectors of all the tokens in the document \"\"\"\n",
    "    \n",
    "    doc_embedding_df = [] # Contains document embeddings for all the articles\n",
    "    assert isinstance(embeddings, pd.DataFrame), 'embeddings must be a pd.DataFrame'\n",
    "    \n",
    "    # This is a trick we use to quickly get the text preprocessed by the tokenizer\n",
    "    # We first convert text to a sequences, and then back to text, which will give the\n",
    "    # preprocessed tokens\n",
    "    sequences = tokenizer.texts_to_sequences(texts)    \n",
    "    preprocessed_texts = tokenizer.sequences_to_texts(sequences)\n",
    "    \n",
    "    # For each text,\n",
    "    for text in preprocessed_texts:\n",
    "        # Make sure we had matches for tokens in the embedding matrx\n",
    "        assert embeddings.loc[text.split(' '), :].shape[0]>0\n",
    "        # Compute mean of all the embeddings associated with words\n",
    "        mean_embedding = embeddings.loc[text.split(' '), :].mean(axis=0)\n",
    "        # Add that to list\n",
    "        doc_embedding_df.append(mean_embedding)\n",
    "        \n",
    "    # Save the doc embeddings in a dataframe\n",
    "    doc_embedding_df = pd.DataFrame(doc_embedding_df, index=filenames)\n",
    "    \n",
    "    return doc_embedding_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4088f799",
   "metadata": {},
   "source": [
    "## Compute skip-gram based document embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11760c18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>None</th>\n",
       "      <td>-1.316333</td>\n",
       "      <td>-1.221975</td>\n",
       "      <td>-0.467647</td>\n",
       "      <td>-1.396968</td>\n",
       "      <td>-1.432016</td>\n",
       "      <td>-1.207448</td>\n",
       "      <td>-1.101838</td>\n",
       "      <td>1.052194</td>\n",
       "      <td>1.072836</td>\n",
       "      <td>-1.528851</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.390015</td>\n",
       "      <td>1.239915</td>\n",
       "      <td>1.274788</td>\n",
       "      <td>1.049227</td>\n",
       "      <td>-1.104107</td>\n",
       "      <td>-1.243190</td>\n",
       "      <td>0.939885</td>\n",
       "      <td>-1.421062</td>\n",
       "      <td>-1.499624</td>\n",
       "      <td>-1.080712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>-0.412803</td>\n",
       "      <td>-0.035928</td>\n",
       "      <td>0.288849</td>\n",
       "      <td>-0.363882</td>\n",
       "      <td>-0.305106</td>\n",
       "      <td>0.205149</td>\n",
       "      <td>0.091930</td>\n",
       "      <td>-0.010472</td>\n",
       "      <td>0.132615</td>\n",
       "      <td>-0.408150</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.284370</td>\n",
       "      <td>0.087606</td>\n",
       "      <td>0.137417</td>\n",
       "      <td>0.043261</td>\n",
       "      <td>-0.481205</td>\n",
       "      <td>0.123714</td>\n",
       "      <td>-0.569555</td>\n",
       "      <td>-0.451168</td>\n",
       "      <td>-0.352354</td>\n",
       "      <td>0.011649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>-0.194968</td>\n",
       "      <td>0.093303</td>\n",
       "      <td>-0.584173</td>\n",
       "      <td>-0.078631</td>\n",
       "      <td>-0.209103</td>\n",
       "      <td>0.010848</td>\n",
       "      <td>-0.154229</td>\n",
       "      <td>1.031888</td>\n",
       "      <td>-0.229217</td>\n",
       "      <td>-0.293748</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.222775</td>\n",
       "      <td>-0.015692</td>\n",
       "      <td>0.392113</td>\n",
       "      <td>-0.095261</td>\n",
       "      <td>-0.051168</td>\n",
       "      <td>0.047403</td>\n",
       "      <td>0.038055</td>\n",
       "      <td>0.001454</td>\n",
       "      <td>-0.400580</td>\n",
       "      <td>-0.290883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>-0.198526</td>\n",
       "      <td>0.067451</td>\n",
       "      <td>0.037129</td>\n",
       "      <td>-0.291451</td>\n",
       "      <td>0.053430</td>\n",
       "      <td>-0.104727</td>\n",
       "      <td>-1.284974</td>\n",
       "      <td>0.083238</td>\n",
       "      <td>-0.267700</td>\n",
       "      <td>-0.368171</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.285382</td>\n",
       "      <td>0.328785</td>\n",
       "      <td>0.095541</td>\n",
       "      <td>0.476249</td>\n",
       "      <td>-0.276102</td>\n",
       "      <td>-0.795023</td>\n",
       "      <td>0.751375</td>\n",
       "      <td>0.004050</td>\n",
       "      <td>-0.303178</td>\n",
       "      <td>-0.524545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>-0.061144</td>\n",
       "      <td>0.084153</td>\n",
       "      <td>0.282463</td>\n",
       "      <td>-0.143367</td>\n",
       "      <td>-0.134334</td>\n",
       "      <td>0.124301</td>\n",
       "      <td>0.430935</td>\n",
       "      <td>0.746847</td>\n",
       "      <td>0.072491</td>\n",
       "      <td>-0.579628</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.085016</td>\n",
       "      <td>0.241277</td>\n",
       "      <td>0.676889</td>\n",
       "      <td>-0.034564</td>\n",
       "      <td>0.348457</td>\n",
       "      <td>0.110958</td>\n",
       "      <td>-0.257479</td>\n",
       "      <td>-0.422164</td>\n",
       "      <td>-0.433074</td>\n",
       "      <td>0.312345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>0.136064</td>\n",
       "      <td>0.355507</td>\n",
       "      <td>-0.243120</td>\n",
       "      <td>-0.226366</td>\n",
       "      <td>0.026080</td>\n",
       "      <td>-0.298392</td>\n",
       "      <td>0.006160</td>\n",
       "      <td>0.017019</td>\n",
       "      <td>0.237877</td>\n",
       "      <td>-0.020025</td>\n",
       "      <td>...</td>\n",
       "      <td>0.483521</td>\n",
       "      <td>0.098399</td>\n",
       "      <td>-0.043496</td>\n",
       "      <td>0.092716</td>\n",
       "      <td>0.289546</td>\n",
       "      <td>-0.022778</td>\n",
       "      <td>1.049736</td>\n",
       "      <td>-0.596496</td>\n",
       "      <td>-0.303149</td>\n",
       "      <td>-0.107286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>-0.254484</td>\n",
       "      <td>-0.583910</td>\n",
       "      <td>0.301826</td>\n",
       "      <td>-0.451182</td>\n",
       "      <td>-0.930586</td>\n",
       "      <td>0.086182</td>\n",
       "      <td>-0.615651</td>\n",
       "      <td>0.098293</td>\n",
       "      <td>0.176085</td>\n",
       "      <td>-0.278348</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.150994</td>\n",
       "      <td>0.718540</td>\n",
       "      <td>0.903492</td>\n",
       "      <td>1.238822</td>\n",
       "      <td>0.194144</td>\n",
       "      <td>0.054024</td>\n",
       "      <td>-0.490397</td>\n",
       "      <td>-0.032465</td>\n",
       "      <td>-0.532481</td>\n",
       "      <td>-1.017847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>-0.337662</td>\n",
       "      <td>0.117969</td>\n",
       "      <td>1.056176</td>\n",
       "      <td>0.011870</td>\n",
       "      <td>-0.115448</td>\n",
       "      <td>-0.861911</td>\n",
       "      <td>0.230234</td>\n",
       "      <td>0.011239</td>\n",
       "      <td>-0.439489</td>\n",
       "      <td>-0.371944</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>0.136871</td>\n",
       "      <td>0.095159</td>\n",
       "      <td>0.537449</td>\n",
       "      <td>0.073490</td>\n",
       "      <td>-0.052828</td>\n",
       "      <td>-0.356154</td>\n",
       "      <td>-0.051445</td>\n",
       "      <td>-0.732453</td>\n",
       "      <td>-0.009737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>for</th>\n",
       "      <td>-0.429915</td>\n",
       "      <td>-0.036498</td>\n",
       "      <td>-0.119357</td>\n",
       "      <td>-0.642725</td>\n",
       "      <td>-0.677542</td>\n",
       "      <td>-0.408580</td>\n",
       "      <td>-0.503838</td>\n",
       "      <td>-0.601547</td>\n",
       "      <td>0.102813</td>\n",
       "      <td>-0.135099</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.264239</td>\n",
       "      <td>0.607912</td>\n",
       "      <td>-0.214494</td>\n",
       "      <td>0.478466</td>\n",
       "      <td>-0.792367</td>\n",
       "      <td>0.190519</td>\n",
       "      <td>0.485500</td>\n",
       "      <td>0.049492</td>\n",
       "      <td>-0.454006</td>\n",
       "      <td>0.296545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>-0.673565</td>\n",
       "      <td>-0.409569</td>\n",
       "      <td>1.147624</td>\n",
       "      <td>-0.356622</td>\n",
       "      <td>-0.198234</td>\n",
       "      <td>-0.526193</td>\n",
       "      <td>-1.086224</td>\n",
       "      <td>-0.534911</td>\n",
       "      <td>1.155104</td>\n",
       "      <td>-0.981866</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.055679</td>\n",
       "      <td>-0.028795</td>\n",
       "      <td>-0.278553</td>\n",
       "      <td>-0.205192</td>\n",
       "      <td>-0.057671</td>\n",
       "      <td>-0.376930</td>\n",
       "      <td>-0.744690</td>\n",
       "      <td>-0.250684</td>\n",
       "      <td>0.171369</td>\n",
       "      <td>0.618726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 128 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6    \\\n",
       "None -1.316333 -1.221975 -0.467647 -1.396968 -1.432016 -1.207448 -1.101838   \n",
       "     -0.412803 -0.035928  0.288849 -0.363882 -0.305106  0.205149  0.091930   \n",
       "the  -0.194968  0.093303 -0.584173 -0.078631 -0.209103  0.010848 -0.154229   \n",
       "to   -0.198526  0.067451  0.037129 -0.291451  0.053430 -0.104727 -1.284974   \n",
       "of   -0.061144  0.084153  0.282463 -0.143367 -0.134334  0.124301  0.430935   \n",
       "and   0.136064  0.355507 -0.243120 -0.226366  0.026080 -0.298392  0.006160   \n",
       "a    -0.254484 -0.583910  0.301826 -0.451182 -0.930586  0.086182 -0.615651   \n",
       "in   -0.337662  0.117969  1.056176  0.011870 -0.115448 -0.861911  0.230234   \n",
       "for  -0.429915 -0.036498 -0.119357 -0.642725 -0.677542 -0.408580 -0.503838   \n",
       "is   -0.673565 -0.409569  1.147624 -0.356622 -0.198234 -0.526193 -1.086224   \n",
       "\n",
       "           7         8         9    ...       118       119       120  \\\n",
       "None  1.052194  1.072836 -1.528851  ... -1.390015  1.239915  1.274788   \n",
       "     -0.010472  0.132615 -0.408150  ... -0.284370  0.087606  0.137417   \n",
       "the   1.031888 -0.229217 -0.293748  ... -0.222775 -0.015692  0.392113   \n",
       "to    0.083238 -0.267700 -0.368171  ... -0.285382  0.328785  0.095541   \n",
       "of    0.746847  0.072491 -0.579628  ... -0.085016  0.241277  0.676889   \n",
       "and   0.017019  0.237877 -0.020025  ...  0.483521  0.098399 -0.043496   \n",
       "a     0.098293  0.176085 -0.278348  ... -0.150994  0.718540  0.903492   \n",
       "in    0.011239 -0.439489 -0.371944  ...  0.015385  0.136871  0.095159   \n",
       "for  -0.601547  0.102813 -0.135099  ... -0.264239  0.607912 -0.214494   \n",
       "is   -0.534911  1.155104 -0.981866  ... -1.055679 -0.028795 -0.278553   \n",
       "\n",
       "           121       122       123       124       125       126       127  \n",
       "None  1.049227 -1.104107 -1.243190  0.939885 -1.421062 -1.499624 -1.080712  \n",
       "      0.043261 -0.481205  0.123714 -0.569555 -0.451168 -0.352354  0.011649  \n",
       "the  -0.095261 -0.051168  0.047403  0.038055  0.001454 -0.400580 -0.290883  \n",
       "to    0.476249 -0.276102 -0.795023  0.751375  0.004050 -0.303178 -0.524545  \n",
       "of   -0.034564  0.348457  0.110958 -0.257479 -0.422164 -0.433074  0.312345  \n",
       "and   0.092716  0.289546 -0.022778  1.049736 -0.596496 -0.303149 -0.107286  \n",
       "a     1.238822  0.194144  0.054024 -0.490397 -0.032465 -0.532481 -1.017847  \n",
       "in    0.537449  0.073490 -0.052828 -0.356154 -0.051445 -0.732453 -0.009737  \n",
       "for   0.478466 -0.792367  0.190519  0.485500  0.049492 -0.454006  0.296545  \n",
       "is   -0.205192 -0.057671 -0.376930 -0.744690 -0.250684  0.171369  0.618726  \n",
       "\n",
       "[10 rows x 128 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the skip-gram embeddings context and target\n",
    "# skipgram_context_embeddings = pd.read_pickle(\n",
    "#     os.path.join('../Ch03-Word-Vectors/skipgram_embeddings', 'context_embedding.pkl')\n",
    "# )\n",
    "# skipgram_target_embeddings = pd.read_pickle(\n",
    "#     os.path.join('../Ch03-Word-Vectors/skipgram_embeddings', 'target_embedding.pkl')\n",
    "# )\n",
    "\n",
    "skipgram_context_embeddings = pd.read_pickle(\n",
    "    os.path.join('skipgram_embeddings', 'context_embedding.pkl')\n",
    ")\n",
    "\n",
    "skipgram_target_embeddings = pd.read_pickle(\n",
    "    os.path.join('skipgram_embeddings', 'target_embedding.pkl')\n",
    ")\n",
    "\n",
    "skipgram_context_embeddings.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8508fcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the mean of context & target embeddings for better embeddings\n",
    "skipgram_embeddings = (skipgram_context_embeddings + skipgram_target_embeddings)/2\n",
    "# Generate the document embeddings with the average context target embeddings\n",
    "skipgram_doc_embeddings = generate_document_embeddings(news_stories, filenames, tokenizer, skipgram_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29543a4",
   "metadata": {},
   "source": [
    "## Train a document classifier\n",
    "\n",
    "Here we train a simple document classifier, using document embeddings as inputs and labels we generated as targets. To get a consistent measure, we will run several trials.\n",
    "\n",
    "---\n",
    "*Document classifier*\n",
    "\n",
    "![Document classifier](notebook_images/04_06.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25b3ba1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     0         1         2         3    \\\n",
      "data/bbc/business/313.txt      -0.074537 -0.022835 -0.049338 -0.067668   \n",
      "data/bbc/entertainment/045.txt -0.082740 -0.084647  0.008997 -0.080020   \n",
      "data/bbc/entertainment/197.txt -0.068181 -0.053321 -0.016951 -0.080832   \n",
      "data/bbc/sport/100.txt         -0.060590 -0.045593 -0.021484 -0.075009   \n",
      "data/bbc/sport/378.txt         -0.059777 -0.085243  0.024250 -0.088373   \n",
      "...                                  ...       ...       ...       ...   \n",
      "data/bbc/sport/055.txt         -0.082552 -0.047622 -0.017358 -0.071503   \n",
      "data/bbc/entertainment/001.txt -0.082694 -0.049631 -0.035745 -0.082065   \n",
      "data/bbc/tech/369.txt          -0.081587 -0.042815 -0.004183 -0.091311   \n",
      "data/bbc/entertainment/269.txt -0.060973 -0.060244 -0.019892 -0.076199   \n",
      "data/bbc/sport/431.txt         -0.067782 -0.043888 -0.010045 -0.075900   \n",
      "\n",
      "                                     4         5         6         7    \\\n",
      "data/bbc/business/313.txt      -0.056686 -0.052644 -0.085258  0.086424   \n",
      "data/bbc/entertainment/045.txt -0.076902 -0.033086  0.009074  0.057506   \n",
      "data/bbc/entertainment/197.txt -0.056269 -0.066782 -0.064923  0.102921   \n",
      "data/bbc/sport/100.txt         -0.052042 -0.072588 -0.101637  0.087443   \n",
      "data/bbc/sport/378.txt         -0.065329 -0.034225  0.016085  0.030757   \n",
      "...                                  ...       ...       ...       ...   \n",
      "data/bbc/sport/055.txt         -0.055340 -0.073016 -0.074222  0.072018   \n",
      "data/bbc/entertainment/001.txt -0.078389 -0.060716 -0.048925  0.066105   \n",
      "data/bbc/tech/369.txt          -0.050232 -0.112021 -0.101971  0.123151   \n",
      "data/bbc/entertainment/269.txt -0.066503 -0.086491 -0.099030  0.071065   \n",
      "data/bbc/sport/431.txt         -0.047261 -0.047998 -0.042978  0.078666   \n",
      "\n",
      "                                     8         9    ...       118       119  \\\n",
      "data/bbc/business/313.txt       0.057295 -0.063544  ... -0.071070  0.061140   \n",
      "data/bbc/entertainment/045.txt  0.045847 -0.074379  ... -0.104908  0.059900   \n",
      "data/bbc/entertainment/197.txt  0.059939 -0.087177  ... -0.073506  0.062244   \n",
      "data/bbc/sport/100.txt          0.028725 -0.065185  ... -0.113585  0.094676   \n",
      "data/bbc/sport/378.txt          0.036477 -0.057022  ... -0.050945  0.028021   \n",
      "...                                  ...       ...  ...       ...       ...   \n",
      "data/bbc/sport/055.txt          0.041696 -0.052208  ... -0.106526  0.103907   \n",
      "data/bbc/entertainment/001.txt  0.051239 -0.088667  ... -0.076886  0.058107   \n",
      "data/bbc/tech/369.txt           0.080600 -0.060161  ... -0.038396  0.123892   \n",
      "data/bbc/entertainment/269.txt  0.028823 -0.100899  ... -0.109618  0.091409   \n",
      "data/bbc/sport/431.txt          0.049667 -0.049842  ... -0.074609  0.031309   \n",
      "\n",
      "                                     120       121       122       123  \\\n",
      "data/bbc/business/313.txt       0.058227  0.061328 -0.063893 -0.037034   \n",
      "data/bbc/entertainment/045.txt  0.063409  0.101468 -0.060670 -0.006376   \n",
      "data/bbc/entertainment/197.txt  0.085651  0.060400 -0.052266 -0.071876   \n",
      "data/bbc/sport/100.txt          0.068793  0.058381 -0.077659 -0.094862   \n",
      "data/bbc/sport/378.txt          0.038158  0.042484 -0.051116 -0.048347   \n",
      "...                                  ...       ...       ...       ...   \n",
      "data/bbc/sport/055.txt          0.055952  0.083190 -0.046040 -0.104170   \n",
      "data/bbc/entertainment/001.txt  0.052442  0.035774 -0.083638 -0.022062   \n",
      "data/bbc/tech/369.txt           0.077919  0.083624 -0.061073 -0.072169   \n",
      "data/bbc/entertainment/269.txt  0.102892  0.063390 -0.067199 -0.050460   \n",
      "data/bbc/sport/431.txt          0.049619  0.074429 -0.034151 -0.075759   \n",
      "\n",
      "                                     124       125       126       127  \n",
      "data/bbc/business/313.txt       0.036828 -0.025789 -0.084894 -0.055655  \n",
      "data/bbc/entertainment/045.txt -0.035801 -0.068300 -0.065707 -0.028159  \n",
      "data/bbc/entertainment/197.txt  0.076951 -0.055076 -0.099331 -0.095441  \n",
      "data/bbc/sport/100.txt          0.131806 -0.046670 -0.095846 -0.114844  \n",
      "data/bbc/sport/378.txt          0.016224 -0.060836 -0.079229 -0.039503  \n",
      "...                                  ...       ...       ...       ...  \n",
      "data/bbc/sport/055.txt          0.134175 -0.038892 -0.113696 -0.108952  \n",
      "data/bbc/entertainment/001.txt -0.023728 -0.052599 -0.095624 -0.056239  \n",
      "data/bbc/tech/369.txt           0.045146 -0.055896 -0.073581 -0.079113  \n",
      "data/bbc/entertainment/269.txt  0.064712 -0.061938 -0.097790 -0.093166  \n",
      "data/bbc/sport/431.txt          0.044242 -0.033022 -0.090088 -0.075296  \n",
      "\n",
      "[1490 rows x 128 columns]\n",
      "data/bbc/business/313.txt         0\n",
      "data/bbc/entertainment/045.txt    1\n",
      "data/bbc/entertainment/197.txt    1\n",
      "data/bbc/sport/100.txt            3\n",
      "data/bbc/sport/378.txt            3\n",
      "                                 ..\n",
      "data/bbc/sport/055.txt            3\n",
      "data/bbc/entertainment/001.txt    1\n",
      "data/bbc/tech/369.txt             4\n",
      "data/bbc/entertainment/269.txt    1\n",
      "data/bbc/sport/431.txt            3\n",
      "Name: 2, Length: 1490, dtype: int64\n",
      "Skip-gram accuracies: [0.8802721088435375, 0.8802721088435375, 0.8802721088435375, 0.8802721088435375, 0.8802721088435375]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def get_classification_accuracy(doc_embeddings, train_labels, test_labels, n_trials):\n",
    "    \"\"\" Train a simple MLP model for several trials and measure test accuracy\"\"\"\n",
    "    \n",
    "    accuracies = [] # Store accuracies across trials\n",
    "    \n",
    "    print(doc_embeddings.loc[train_labels.index])\n",
    "    print(train_labels.astype('int'))\n",
    "    # For each trial\n",
    "    for trial in range(n_trials):\n",
    "        # Create a MLP classifier\n",
    "        lr_classifier = LogisticRegression(multi_class='multinomial', max_iter=500)\n",
    "        \n",
    "        # Fit the model on training data\n",
    "        lr_classifier.fit(doc_embeddings.loc[train_labels.index], train_labels)\n",
    "        \n",
    "        # Get the predictions for test data\n",
    "        predictions = lr_classifier.predict(doc_embeddings.loc[test_labels.index])\n",
    "    \n",
    "        # Compute accuracy\n",
    "        accuracies.append(accuracy_score(predictions, test_labels))\n",
    "    \n",
    "    return accuracies\n",
    "\n",
    "# Get classification accuracy for skip-gram models\n",
    "skipgram_accuracies = get_classification_accuracy(\n",
    "    skipgram_doc_embeddings, train_labels.astype('int'), test_labels.astype('int'), n_trials=5\n",
    ")\n",
    "\n",
    "print(f\"Skip-gram accuracies: {skipgram_accuracies}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3aec63b",
   "metadata": {},
   "source": [
    "## Train a classifier on CBOW based document embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1eeb9bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cbow_context_embeddings = pd.read_pickle(\n",
    "#     os.path.join('../Ch03-Word-Vectors/cbow_embeddings', 'context_embedding.pkl')\n",
    "# )\n",
    "# cbow_target_embeddings = pd.read_pickle(\n",
    "#     os.path.join('../Ch03-Word-Vectors/cbow_embeddings', 'target_embedding.pkl')\n",
    "# )\n",
    "\n",
    "\n",
    "cbow_context_embeddings = pd.read_pickle(\n",
    "    os.path.join('cbow_embeddings', 'context_embedding.pkl')\n",
    ")\n",
    "\n",
    "cbow_target_embeddings = pd.read_pickle(\n",
    "    os.path.join('cbow_embeddings', 'target_embedding.pkl')\n",
    ")\n",
    "\n",
    "\n",
    "cbow_embeddings = (cbow_context_embeddings + cbow_target_embeddings)/2\n",
    "cbow_doc_embeddings = generate_document_embeddings(news_stories, filenames, tokenizer, cbow_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf065086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     0         1         2         3    \\\n",
      "data/bbc/business/313.txt      -0.080031  0.124552 -0.090819 -0.068457   \n",
      "data/bbc/entertainment/045.txt -0.041774  0.058377 -0.056427 -0.046418   \n",
      "data/bbc/entertainment/197.txt -0.071520  0.088465 -0.080754 -0.088848   \n",
      "data/bbc/sport/100.txt         -0.087848  0.098416 -0.091055 -0.080063   \n",
      "data/bbc/sport/378.txt         -0.073222  0.037675 -0.034639 -0.054382   \n",
      "...                                  ...       ...       ...       ...   \n",
      "data/bbc/sport/055.txt         -0.068862  0.067742 -0.108815 -0.074146   \n",
      "data/bbc/entertainment/001.txt -0.077338  0.104004 -0.109309 -0.068990   \n",
      "data/bbc/tech/369.txt          -0.067491  0.078481 -0.062365 -0.093093   \n",
      "data/bbc/entertainment/269.txt -0.087191  0.097004 -0.117959 -0.094483   \n",
      "data/bbc/sport/431.txt         -0.070375  0.060200 -0.071131 -0.095909   \n",
      "\n",
      "                                     4         5         6         7    \\\n",
      "data/bbc/business/313.txt      -0.050499 -0.076633 -0.067303 -0.067737   \n",
      "data/bbc/entertainment/045.txt -0.086877 -0.048163 -0.017948 -0.022934   \n",
      "data/bbc/entertainment/197.txt -0.089409 -0.093189 -0.088716 -0.068926   \n",
      "data/bbc/sport/100.txt         -0.081840 -0.106378 -0.097040 -0.091707   \n",
      "data/bbc/sport/378.txt         -0.094260 -0.079538 -0.055222 -0.053540   \n",
      "...                                  ...       ...       ...       ...   \n",
      "data/bbc/sport/055.txt         -0.083233 -0.105533 -0.098146 -0.073369   \n",
      "data/bbc/entertainment/001.txt -0.104765 -0.084768 -0.070650 -0.053168   \n",
      "data/bbc/tech/369.txt          -0.046680 -0.056577 -0.064071 -0.062932   \n",
      "data/bbc/entertainment/269.txt -0.090787 -0.104756 -0.086639 -0.089647   \n",
      "data/bbc/sport/431.txt         -0.081246 -0.078304 -0.066437 -0.062221   \n",
      "\n",
      "                                     8         9    ...       118       119  \\\n",
      "data/bbc/business/313.txt       0.084069 -0.043949  ... -0.102129  0.053829   \n",
      "data/bbc/entertainment/045.txt  0.043518 -0.066032  ... -0.059260  0.088919   \n",
      "data/bbc/entertainment/197.txt  0.093056 -0.085097  ... -0.089603  0.057435   \n",
      "data/bbc/sport/100.txt          0.082299 -0.070787  ... -0.128977  0.057873   \n",
      "data/bbc/sport/378.txt          0.067677 -0.111353  ... -0.055938  0.021289   \n",
      "...                                  ...       ...  ...       ...       ...   \n",
      "data/bbc/sport/055.txt          0.057685 -0.054987  ... -0.110266  0.052727   \n",
      "data/bbc/entertainment/001.txt  0.093940 -0.074552  ... -0.078587  0.088246   \n",
      "data/bbc/tech/369.txt           0.087948 -0.036611  ... -0.073688  0.034099   \n",
      "data/bbc/entertainment/269.txt  0.065739 -0.078885  ... -0.116514  0.081833   \n",
      "data/bbc/sport/431.txt          0.063842 -0.069943  ... -0.066423  0.086525   \n",
      "\n",
      "                                     120       121       122       123  \\\n",
      "data/bbc/business/313.txt       0.094615  0.047075  0.061099 -0.055169   \n",
      "data/bbc/entertainment/045.txt  0.102882  0.068616  0.030914 -0.030726   \n",
      "data/bbc/entertainment/197.txt  0.084486  0.076019  0.082409 -0.074228   \n",
      "data/bbc/sport/100.txt          0.094863  0.064016  0.098923 -0.072449   \n",
      "data/bbc/sport/378.txt          0.064465  0.048136  0.060871 -0.039790   \n",
      "...                                  ...       ...       ...       ...   \n",
      "data/bbc/sport/055.txt          0.102053  0.085085  0.107406 -0.075458   \n",
      "data/bbc/entertainment/001.txt  0.117551  0.079086  0.047743 -0.053524   \n",
      "data/bbc/tech/369.txt           0.079079  0.101098  0.061747 -0.076709   \n",
      "data/bbc/entertainment/269.txt  0.121000  0.082963  0.096444 -0.078384   \n",
      "data/bbc/sport/431.txt          0.071018  0.060066  0.084014 -0.095306   \n",
      "\n",
      "                                     124       125       126       127  \n",
      "data/bbc/business/313.txt      -0.103541 -0.061240 -0.082702  0.098251  \n",
      "data/bbc/entertainment/045.txt -0.102272 -0.131106 -0.054523  0.098033  \n",
      "data/bbc/entertainment/197.txt -0.083069 -0.061336 -0.101311  0.083458  \n",
      "data/bbc/sport/100.txt         -0.065848 -0.069423 -0.095268  0.048999  \n",
      "data/bbc/sport/378.txt         -0.087720 -0.118150 -0.093548  0.057236  \n",
      "...                                  ...       ...       ...       ...  \n",
      "data/bbc/sport/055.txt         -0.065277 -0.065573 -0.113353  0.015125  \n",
      "data/bbc/entertainment/001.txt -0.105640 -0.098897 -0.081313  0.089377  \n",
      "data/bbc/tech/369.txt          -0.073898 -0.049554 -0.058014  0.104408  \n",
      "data/bbc/entertainment/269.txt -0.072268 -0.078303 -0.087571  0.072079  \n",
      "data/bbc/sport/431.txt         -0.086588 -0.093274 -0.092523  0.047649  \n",
      "\n",
      "[1490 rows x 128 columns]\n",
      "data/bbc/business/313.txt         0\n",
      "data/bbc/entertainment/045.txt    1\n",
      "data/bbc/entertainment/197.txt    1\n",
      "data/bbc/sport/100.txt            3\n",
      "data/bbc/sport/378.txt            3\n",
      "                                 ..\n",
      "data/bbc/sport/055.txt            3\n",
      "data/bbc/entertainment/001.txt    1\n",
      "data/bbc/tech/369.txt             4\n",
      "data/bbc/entertainment/269.txt    1\n",
      "data/bbc/sport/431.txt            3\n",
      "Name: 2, Length: 1490, dtype: int64\n",
      "[0.8421768707482993, 0.8421768707482993, 0.8421768707482993, 0.8421768707482993, 0.8421768707482993]\n"
     ]
    }
   ],
   "source": [
    "cbow_accuracies = get_classification_accuracy(\n",
    "    cbow_doc_embeddings, train_labels, test_labels, n_trials=5\n",
    ")\n",
    "print(cbow_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14000a4d",
   "metadata": {},
   "source": [
    "## Train a classifier on GloVe embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e383884c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# glove_context_embeddings = pd.read_pickle(\n",
    "#     os.path.join('glove_embeddings', 'context_embedding_and_bias.pkl')\n",
    "# )\n",
    "# glove_target_embeddings = pd.read_pickle(\n",
    "#     os.path.join('glove_embeddings', 'target_embedding_and_bias.pkl')\n",
    "# )\n",
    "\n",
    "glove_context_embeddings = pd.read_pickle(\n",
    "    os.path.join('glove_embeddings', 'context_embedding_and_bias.pkl')\n",
    ")\n",
    "\n",
    "glove_target_embeddings = pd.read_pickle(\n",
    "    os.path.join('glove_embeddings', 'target_embedding_and_bias.pkl')\n",
    ")\n",
    "\n",
    "glove_embeddings = (glove_context_embeddings.iloc[:, :-1] + glove_target_embeddings.iloc[:, :-1])/2\n",
    "glove_doc_embeddings = generate_document_embeddings(news_stories, filenames, tokenizer, glove_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "584e58b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     0         1         2         3    \\\n",
      "data/bbc/business/313.txt       0.106106  0.216254 -0.036073  0.068143   \n",
      "data/bbc/entertainment/045.txt  0.125770  0.180885  0.015304  0.077578   \n",
      "data/bbc/entertainment/197.txt  0.114940  0.205332 -0.032697  0.061498   \n",
      "data/bbc/sport/100.txt          0.114397  0.205747 -0.053286  0.052973   \n",
      "data/bbc/sport/378.txt          0.105602  0.178900 -0.012490  0.044315   \n",
      "...                                  ...       ...       ...       ...   \n",
      "data/bbc/sport/055.txt          0.111029  0.195338 -0.059469  0.051265   \n",
      "data/bbc/entertainment/001.txt  0.127385  0.218446 -0.019569  0.070928   \n",
      "data/bbc/tech/369.txt           0.108568  0.188743 -0.038029  0.059675   \n",
      "data/bbc/entertainment/269.txt  0.136771  0.216713 -0.031295  0.068399   \n",
      "data/bbc/sport/431.txt          0.096833  0.201042 -0.024751  0.058077   \n",
      "\n",
      "                                     4         5         6         7    \\\n",
      "data/bbc/business/313.txt       0.083994 -0.149094 -0.181892 -0.193175   \n",
      "data/bbc/entertainment/045.txt  0.036583 -0.137953 -0.153914 -0.168557   \n",
      "data/bbc/entertainment/197.txt  0.065793 -0.145519 -0.172722 -0.166693   \n",
      "data/bbc/sport/100.txt          0.078745 -0.153888 -0.165908 -0.176794   \n",
      "data/bbc/sport/378.txt          0.060598 -0.124813 -0.154483 -0.166174   \n",
      "...                                  ...       ...       ...       ...   \n",
      "data/bbc/sport/055.txt          0.064524 -0.149179 -0.156224 -0.169728   \n",
      "data/bbc/entertainment/001.txt  0.034782 -0.152216 -0.192074 -0.183165   \n",
      "data/bbc/tech/369.txt           0.084707 -0.140398 -0.162710 -0.150358   \n",
      "data/bbc/entertainment/269.txt  0.060708 -0.163859 -0.180476 -0.192803   \n",
      "data/bbc/sport/431.txt          0.076939 -0.134829 -0.157715 -0.173900   \n",
      "\n",
      "                                     8         9    ...       118       119  \\\n",
      "data/bbc/business/313.txt      -0.062618 -0.165131  ... -0.152364 -0.100625   \n",
      "data/bbc/entertainment/045.txt -0.063918 -0.144618  ... -0.135096 -0.076875   \n",
      "data/bbc/entertainment/197.txt -0.062092 -0.159015  ... -0.148890 -0.085678   \n",
      "data/bbc/sport/100.txt         -0.069796 -0.151446  ... -0.167795 -0.070318   \n",
      "data/bbc/sport/378.txt         -0.074726 -0.138989  ... -0.133721 -0.087233   \n",
      "...                                  ...       ...  ...       ...       ...   \n",
      "data/bbc/sport/055.txt         -0.050228 -0.137479  ... -0.140922 -0.062679   \n",
      "data/bbc/entertainment/001.txt -0.062281 -0.161313  ... -0.166780 -0.096913   \n",
      "data/bbc/tech/369.txt          -0.038578 -0.151674  ... -0.133268 -0.072715   \n",
      "data/bbc/entertainment/269.txt -0.073635 -0.160097  ... -0.173987 -0.084200   \n",
      "data/bbc/sport/431.txt         -0.052452 -0.146203  ... -0.136922 -0.085839   \n",
      "\n",
      "                                     120       121       122       123  \\\n",
      "data/bbc/business/313.txt      -0.004636  0.064424 -0.110103  0.192603   \n",
      "data/bbc/entertainment/045.txt  0.013317  0.070405 -0.080155  0.169002   \n",
      "data/bbc/entertainment/197.txt -0.000831  0.080209 -0.096949  0.179591   \n",
      "data/bbc/sport/100.txt         -0.006689  0.080135 -0.109797  0.184955   \n",
      "data/bbc/sport/378.txt         -0.012417  0.054287 -0.109256  0.170157   \n",
      "...                                  ...       ...       ...       ...   \n",
      "data/bbc/sport/055.txt          0.006357  0.094249 -0.092026  0.174478   \n",
      "data/bbc/entertainment/001.txt -0.004247  0.070891 -0.108065  0.198498   \n",
      "data/bbc/tech/369.txt           0.023094  0.085498 -0.094890  0.160938   \n",
      "data/bbc/entertainment/269.txt  0.019676  0.073011 -0.103132  0.200596   \n",
      "data/bbc/sport/431.txt         -0.012214  0.079220 -0.091136  0.164399   \n",
      "\n",
      "                                     124       125       126       127  \n",
      "data/bbc/business/313.txt       0.175576  0.182687 -0.192113 -0.076141  \n",
      "data/bbc/entertainment/045.txt  0.148260  0.150046 -0.143895 -0.053790  \n",
      "data/bbc/entertainment/197.txt  0.173217  0.168487 -0.179876 -0.076488  \n",
      "data/bbc/sport/100.txt          0.180305  0.174103 -0.175996 -0.079166  \n",
      "data/bbc/sport/378.txt          0.145107  0.160653 -0.154272 -0.069624  \n",
      "...                                  ...       ...       ...       ...  \n",
      "data/bbc/sport/055.txt          0.173315  0.163184 -0.174842 -0.074132  \n",
      "data/bbc/entertainment/001.txt  0.179430  0.188061 -0.179970 -0.067574  \n",
      "data/bbc/tech/369.txt           0.161810  0.159475 -0.165095 -0.058253  \n",
      "data/bbc/entertainment/269.txt  0.189732  0.182412 -0.182234 -0.060885  \n",
      "data/bbc/sport/431.txt          0.159576  0.172957 -0.171846 -0.071914  \n",
      "\n",
      "[1490 rows x 128 columns]\n",
      "data/bbc/business/313.txt         0\n",
      "data/bbc/entertainment/045.txt    1\n",
      "data/bbc/entertainment/197.txt    1\n",
      "data/bbc/sport/100.txt            3\n",
      "data/bbc/sport/378.txt            3\n",
      "                                 ..\n",
      "data/bbc/sport/055.txt            3\n",
      "data/bbc/entertainment/001.txt    1\n",
      "data/bbc/tech/369.txt             4\n",
      "data/bbc/entertainment/269.txt    1\n",
      "data/bbc/sport/431.txt            3\n",
      "Name: 2, Length: 1490, dtype: int64\n",
      "[0.6979591836734694, 0.6979591836734694, 0.6979591836734694, 0.6979591836734694, 0.6979591836734694]\n"
     ]
    }
   ],
   "source": [
    "glove_accuracies = get_classification_accuracy(\n",
    "    glove_doc_embeddings, train_labels, test_labels, n_trials=5\n",
    ")\n",
    "print(glove_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193f8174",
   "metadata": {},
   "source": [
    "## Train a classifier on ELMo document embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1973783f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1014</th>\n",
       "      <th>1015</th>\n",
       "      <th>1016</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>1023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>data/bbc/tech/174.txt</th>\n",
       "      <td>0.012744</td>\n",
       "      <td>0.023062</td>\n",
       "      <td>-0.035946</td>\n",
       "      <td>-0.090556</td>\n",
       "      <td>0.144047</td>\n",
       "      <td>0.166769</td>\n",
       "      <td>0.017964</td>\n",
       "      <td>0.342860</td>\n",
       "      <td>-0.161670</td>\n",
       "      <td>-0.082526</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.340656</td>\n",
       "      <td>0.244855</td>\n",
       "      <td>0.030709</td>\n",
       "      <td>0.253689</td>\n",
       "      <td>0.078406</td>\n",
       "      <td>0.044581</td>\n",
       "      <td>0.372656</td>\n",
       "      <td>-0.006501</td>\n",
       "      <td>0.273694</td>\n",
       "      <td>0.057726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data/bbc/tech/170.txt</th>\n",
       "      <td>0.256800</td>\n",
       "      <td>-0.076643</td>\n",
       "      <td>-0.005060</td>\n",
       "      <td>-0.063172</td>\n",
       "      <td>0.138440</td>\n",
       "      <td>0.189914</td>\n",
       "      <td>0.182261</td>\n",
       "      <td>0.326142</td>\n",
       "      <td>-0.117797</td>\n",
       "      <td>0.026969</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.171903</td>\n",
       "      <td>0.165076</td>\n",
       "      <td>-0.113165</td>\n",
       "      <td>0.327153</td>\n",
       "      <td>0.209255</td>\n",
       "      <td>0.082908</td>\n",
       "      <td>0.258461</td>\n",
       "      <td>-0.122383</td>\n",
       "      <td>0.307110</td>\n",
       "      <td>-0.029122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data/bbc/tech/302.txt</th>\n",
       "      <td>0.178142</td>\n",
       "      <td>0.275478</td>\n",
       "      <td>-0.044081</td>\n",
       "      <td>0.069659</td>\n",
       "      <td>0.219834</td>\n",
       "      <td>0.160469</td>\n",
       "      <td>-0.008855</td>\n",
       "      <td>0.358277</td>\n",
       "      <td>0.126847</td>\n",
       "      <td>-0.048421</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.290554</td>\n",
       "      <td>0.097650</td>\n",
       "      <td>-0.033120</td>\n",
       "      <td>0.317354</td>\n",
       "      <td>-0.011647</td>\n",
       "      <td>0.147325</td>\n",
       "      <td>0.441159</td>\n",
       "      <td>-0.065567</td>\n",
       "      <td>0.119717</td>\n",
       "      <td>-0.027908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data/bbc/tech/256.txt</th>\n",
       "      <td>0.113356</td>\n",
       "      <td>-0.150963</td>\n",
       "      <td>-0.054547</td>\n",
       "      <td>0.078308</td>\n",
       "      <td>0.010922</td>\n",
       "      <td>0.414599</td>\n",
       "      <td>-0.085480</td>\n",
       "      <td>0.392278</td>\n",
       "      <td>0.147020</td>\n",
       "      <td>-0.126910</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.291242</td>\n",
       "      <td>0.131670</td>\n",
       "      <td>0.126649</td>\n",
       "      <td>0.161829</td>\n",
       "      <td>0.085308</td>\n",
       "      <td>0.041790</td>\n",
       "      <td>0.132907</td>\n",
       "      <td>-0.010835</td>\n",
       "      <td>0.489633</td>\n",
       "      <td>-0.170547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data/bbc/tech/211.txt</th>\n",
       "      <td>0.161718</td>\n",
       "      <td>0.072896</td>\n",
       "      <td>-0.033089</td>\n",
       "      <td>-0.112782</td>\n",
       "      <td>0.426878</td>\n",
       "      <td>0.299916</td>\n",
       "      <td>0.084742</td>\n",
       "      <td>0.284771</td>\n",
       "      <td>-0.164555</td>\n",
       "      <td>0.051139</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.091179</td>\n",
       "      <td>0.205737</td>\n",
       "      <td>-0.067422</td>\n",
       "      <td>0.088594</td>\n",
       "      <td>0.118239</td>\n",
       "      <td>0.079229</td>\n",
       "      <td>0.402150</td>\n",
       "      <td>-0.011402</td>\n",
       "      <td>0.355481</td>\n",
       "      <td>-0.067534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data/bbc/tech/326.txt</th>\n",
       "      <td>0.312790</td>\n",
       "      <td>0.138870</td>\n",
       "      <td>-0.076327</td>\n",
       "      <td>-0.154205</td>\n",
       "      <td>0.167426</td>\n",
       "      <td>0.080995</td>\n",
       "      <td>-0.002776</td>\n",
       "      <td>0.164310</td>\n",
       "      <td>-0.102516</td>\n",
       "      <td>-0.095217</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.307079</td>\n",
       "      <td>0.203746</td>\n",
       "      <td>0.135431</td>\n",
       "      <td>0.132567</td>\n",
       "      <td>-0.003398</td>\n",
       "      <td>0.045161</td>\n",
       "      <td>0.251887</td>\n",
       "      <td>-0.018399</td>\n",
       "      <td>0.091552</td>\n",
       "      <td>-0.091546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data/bbc/tech/363.txt</th>\n",
       "      <td>0.051522</td>\n",
       "      <td>-0.116508</td>\n",
       "      <td>0.021444</td>\n",
       "      <td>-0.132232</td>\n",
       "      <td>0.174894</td>\n",
       "      <td>0.095304</td>\n",
       "      <td>0.127901</td>\n",
       "      <td>0.435579</td>\n",
       "      <td>0.012038</td>\n",
       "      <td>-0.146804</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.151405</td>\n",
       "      <td>0.153150</td>\n",
       "      <td>0.066877</td>\n",
       "      <td>0.345065</td>\n",
       "      <td>-0.029675</td>\n",
       "      <td>-0.109978</td>\n",
       "      <td>0.193816</td>\n",
       "      <td>-0.107168</td>\n",
       "      <td>0.357005</td>\n",
       "      <td>0.030061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data/bbc/tech/134.txt</th>\n",
       "      <td>0.065984</td>\n",
       "      <td>0.055749</td>\n",
       "      <td>0.033957</td>\n",
       "      <td>-0.087867</td>\n",
       "      <td>0.198809</td>\n",
       "      <td>0.185405</td>\n",
       "      <td>0.116618</td>\n",
       "      <td>0.416797</td>\n",
       "      <td>-0.158576</td>\n",
       "      <td>-0.039389</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.207431</td>\n",
       "      <td>0.237969</td>\n",
       "      <td>0.020248</td>\n",
       "      <td>0.474798</td>\n",
       "      <td>0.147314</td>\n",
       "      <td>-0.086313</td>\n",
       "      <td>0.283539</td>\n",
       "      <td>-0.038299</td>\n",
       "      <td>0.322855</td>\n",
       "      <td>-0.083530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data/bbc/tech/050.txt</th>\n",
       "      <td>0.077217</td>\n",
       "      <td>0.065682</td>\n",
       "      <td>0.045798</td>\n",
       "      <td>-0.091198</td>\n",
       "      <td>0.452054</td>\n",
       "      <td>0.358033</td>\n",
       "      <td>0.088634</td>\n",
       "      <td>0.393721</td>\n",
       "      <td>-0.214198</td>\n",
       "      <td>0.206301</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.242007</td>\n",
       "      <td>0.274968</td>\n",
       "      <td>-0.058163</td>\n",
       "      <td>0.344481</td>\n",
       "      <td>0.183206</td>\n",
       "      <td>0.059261</td>\n",
       "      <td>0.382113</td>\n",
       "      <td>-0.144127</td>\n",
       "      <td>0.195141</td>\n",
       "      <td>-0.019669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data/bbc/tech/001.txt</th>\n",
       "      <td>-0.035935</td>\n",
       "      <td>-0.057713</td>\n",
       "      <td>-0.042617</td>\n",
       "      <td>-0.214429</td>\n",
       "      <td>-0.067015</td>\n",
       "      <td>0.157125</td>\n",
       "      <td>0.029188</td>\n",
       "      <td>0.084584</td>\n",
       "      <td>-0.334528</td>\n",
       "      <td>-0.030607</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208489</td>\n",
       "      <td>0.161351</td>\n",
       "      <td>0.008093</td>\n",
       "      <td>0.035859</td>\n",
       "      <td>0.009524</td>\n",
       "      <td>0.140167</td>\n",
       "      <td>0.169122</td>\n",
       "      <td>0.021745</td>\n",
       "      <td>0.425750</td>\n",
       "      <td>0.016636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 1024 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           0         1         2         3         4     \\\n",
       "data/bbc/tech/174.txt  0.012744  0.023062 -0.035946 -0.090556  0.144047   \n",
       "data/bbc/tech/170.txt  0.256800 -0.076643 -0.005060 -0.063172  0.138440   \n",
       "data/bbc/tech/302.txt  0.178142  0.275478 -0.044081  0.069659  0.219834   \n",
       "data/bbc/tech/256.txt  0.113356 -0.150963 -0.054547  0.078308  0.010922   \n",
       "data/bbc/tech/211.txt  0.161718  0.072896 -0.033089 -0.112782  0.426878   \n",
       "data/bbc/tech/326.txt  0.312790  0.138870 -0.076327 -0.154205  0.167426   \n",
       "data/bbc/tech/363.txt  0.051522 -0.116508  0.021444 -0.132232  0.174894   \n",
       "data/bbc/tech/134.txt  0.065984  0.055749  0.033957 -0.087867  0.198809   \n",
       "data/bbc/tech/050.txt  0.077217  0.065682  0.045798 -0.091198  0.452054   \n",
       "data/bbc/tech/001.txt -0.035935 -0.057713 -0.042617 -0.214429 -0.067015   \n",
       "\n",
       "                           5         6         7         8         9     ...  \\\n",
       "data/bbc/tech/174.txt  0.166769  0.017964  0.342860 -0.161670 -0.082526  ...   \n",
       "data/bbc/tech/170.txt  0.189914  0.182261  0.326142 -0.117797  0.026969  ...   \n",
       "data/bbc/tech/302.txt  0.160469 -0.008855  0.358277  0.126847 -0.048421  ...   \n",
       "data/bbc/tech/256.txt  0.414599 -0.085480  0.392278  0.147020 -0.126910  ...   \n",
       "data/bbc/tech/211.txt  0.299916  0.084742  0.284771 -0.164555  0.051139  ...   \n",
       "data/bbc/tech/326.txt  0.080995 -0.002776  0.164310 -0.102516 -0.095217  ...   \n",
       "data/bbc/tech/363.txt  0.095304  0.127901  0.435579  0.012038 -0.146804  ...   \n",
       "data/bbc/tech/134.txt  0.185405  0.116618  0.416797 -0.158576 -0.039389  ...   \n",
       "data/bbc/tech/050.txt  0.358033  0.088634  0.393721 -0.214198  0.206301  ...   \n",
       "data/bbc/tech/001.txt  0.157125  0.029188  0.084584 -0.334528 -0.030607  ...   \n",
       "\n",
       "                           1014      1015      1016      1017      1018  \\\n",
       "data/bbc/tech/174.txt -0.340656  0.244855  0.030709  0.253689  0.078406   \n",
       "data/bbc/tech/170.txt -0.171903  0.165076 -0.113165  0.327153  0.209255   \n",
       "data/bbc/tech/302.txt -0.290554  0.097650 -0.033120  0.317354 -0.011647   \n",
       "data/bbc/tech/256.txt -0.291242  0.131670  0.126649  0.161829  0.085308   \n",
       "data/bbc/tech/211.txt -0.091179  0.205737 -0.067422  0.088594  0.118239   \n",
       "data/bbc/tech/326.txt -0.307079  0.203746  0.135431  0.132567 -0.003398   \n",
       "data/bbc/tech/363.txt -0.151405  0.153150  0.066877  0.345065 -0.029675   \n",
       "data/bbc/tech/134.txt -0.207431  0.237969  0.020248  0.474798  0.147314   \n",
       "data/bbc/tech/050.txt -0.242007  0.274968 -0.058163  0.344481  0.183206   \n",
       "data/bbc/tech/001.txt -0.208489  0.161351  0.008093  0.035859  0.009524   \n",
       "\n",
       "                           1019      1020      1021      1022      1023  \n",
       "data/bbc/tech/174.txt  0.044581  0.372656 -0.006501  0.273694  0.057726  \n",
       "data/bbc/tech/170.txt  0.082908  0.258461 -0.122383  0.307110 -0.029122  \n",
       "data/bbc/tech/302.txt  0.147325  0.441159 -0.065567  0.119717 -0.027908  \n",
       "data/bbc/tech/256.txt  0.041790  0.132907 -0.010835  0.489633 -0.170547  \n",
       "data/bbc/tech/211.txt  0.079229  0.402150 -0.011402  0.355481 -0.067534  \n",
       "data/bbc/tech/326.txt  0.045161  0.251887 -0.018399  0.091552 -0.091546  \n",
       "data/bbc/tech/363.txt -0.109978  0.193816 -0.107168  0.357005  0.030061  \n",
       "data/bbc/tech/134.txt -0.086313  0.283539 -0.038299  0.322855 -0.083530  \n",
       "data/bbc/tech/050.txt  0.059261  0.382113 -0.144127  0.195141 -0.019669  \n",
       "data/bbc/tech/001.txt  0.140167  0.169122  0.021745  0.425750  0.016636  \n",
       "\n",
       "[10 rows x 1024 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elmo_doc_embeddings = pd.read_pickle(\n",
    "    os.path.join('elmo_embeddings', 'elmo_embeddings.pkl')\n",
    ")\n",
    "\n",
    "elmo_doc_embeddings.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e02751f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    0         1         2         3     \\\n",
      "data/bbc/business/313.txt      -0.221736  0.105317  0.081787 -0.274011   \n",
      "data/bbc/entertainment/045.txt -0.323768 -0.031293  0.156228 -0.069630   \n",
      "data/bbc/entertainment/197.txt  0.217634 -0.178705 -0.027458 -0.012849   \n",
      "data/bbc/sport/100.txt         -0.279527 -0.380739 -0.022975 -0.207223   \n",
      "data/bbc/sport/378.txt          0.023839 -0.220556  0.071147  0.039579   \n",
      "...                                  ...       ...       ...       ...   \n",
      "data/bbc/sport/055.txt         -0.157657 -0.122415 -0.136604 -0.054244   \n",
      "data/bbc/entertainment/001.txt -0.033875 -0.151102 -0.111134 -0.189952   \n",
      "data/bbc/tech/369.txt          -0.012196  0.043267 -0.087469  0.017215   \n",
      "data/bbc/entertainment/269.txt -0.186900 -0.080020  0.115196 -0.046049   \n",
      "data/bbc/sport/431.txt         -0.065461 -0.211498  0.017491 -0.044656   \n",
      "\n",
      "                                    4         5         6         7     \\\n",
      "data/bbc/business/313.txt      -0.066592 -0.147126 -0.032872  0.682354   \n",
      "data/bbc/entertainment/045.txt  0.309799  0.346279 -0.127771  0.407712   \n",
      "data/bbc/entertainment/197.txt  0.158261  0.588648 -0.010584  0.272013   \n",
      "data/bbc/sport/100.txt          0.231907  0.364036 -0.171591  0.235586   \n",
      "data/bbc/sport/378.txt          0.397296  0.424515 -0.038503  0.263150   \n",
      "...                                  ...       ...       ...       ...   \n",
      "data/bbc/sport/055.txt          0.211811  0.196852 -0.012371  0.475569   \n",
      "data/bbc/entertainment/001.txt  0.027450  0.170228 -0.054218  0.368672   \n",
      "data/bbc/tech/369.txt           0.186186  0.014798 -0.126888 -0.000285   \n",
      "data/bbc/entertainment/269.txt  0.072138  0.457156 -0.031061  0.170565   \n",
      "data/bbc/sport/431.txt          0.320152  0.191890  0.153383  0.261256   \n",
      "\n",
      "                                    8         9     ...      1014      1015  \\\n",
      "data/bbc/business/313.txt       0.047648  0.136155  ... -0.071582  0.086508   \n",
      "data/bbc/entertainment/045.txt  0.258912 -0.025906  ... -0.213091  0.225307   \n",
      "data/bbc/entertainment/197.txt -0.073465 -0.223971  ... -0.372615  0.078725   \n",
      "data/bbc/sport/100.txt         -0.170954  0.162374  ... -0.135753  0.237234   \n",
      "data/bbc/sport/378.txt          0.009986 -0.044250  ... -0.142057  0.294717   \n",
      "...                                  ...       ...  ...       ...       ...   \n",
      "data/bbc/sport/055.txt         -0.339825 -0.163114  ...  0.098321  0.151976   \n",
      "data/bbc/entertainment/001.txt  0.269478 -0.004138  ... -0.064879  0.199112   \n",
      "data/bbc/tech/369.txt          -0.376950 -0.014225  ... -0.387383  0.122890   \n",
      "data/bbc/entertainment/269.txt  0.057606  0.053081  ... -0.153662  0.182301   \n",
      "data/bbc/sport/431.txt         -0.249631  0.045264  ... -0.118230  0.282956   \n",
      "\n",
      "                                    1016      1017      1018      1019  \\\n",
      "data/bbc/business/313.txt       0.020002 -0.000187  0.418276  0.032905   \n",
      "data/bbc/entertainment/045.txt -0.218816  0.064136  0.028958 -0.046098   \n",
      "data/bbc/entertainment/197.txt -0.001956  0.020701  0.117016  0.094699   \n",
      "data/bbc/sport/100.txt         -0.080529 -0.170919  0.019169 -0.061966   \n",
      "data/bbc/sport/378.txt          0.351377  0.029795  0.301015 -0.024756   \n",
      "...                                  ...       ...       ...       ...   \n",
      "data/bbc/sport/055.txt         -0.252208 -0.123921  0.289295 -0.095315   \n",
      "data/bbc/entertainment/001.txt -0.043191  0.395734 -0.022106  0.225082   \n",
      "data/bbc/tech/369.txt           0.020102  0.223458 -0.002277 -0.056525   \n",
      "data/bbc/entertainment/269.txt -0.347497  0.207037  0.011723  0.006957   \n",
      "data/bbc/sport/431.txt          0.087792 -0.157284  0.135416 -0.141032   \n",
      "\n",
      "                                    1020      1021      1022      1023  \n",
      "data/bbc/business/313.txt      -0.083169 -0.153771  0.665987  0.063013  \n",
      "data/bbc/entertainment/045.txt -0.174888 -0.040931  0.222721 -0.094427  \n",
      "data/bbc/entertainment/197.txt -0.041922 -0.016385  0.508878  0.100692  \n",
      "data/bbc/sport/100.txt          0.262760 -0.046188  0.520973 -0.090225  \n",
      "data/bbc/sport/378.txt          0.261541  0.148069  0.486727  0.105662  \n",
      "...                                  ...       ...       ...       ...  \n",
      "data/bbc/sport/055.txt          0.133397 -0.077265  0.440336  0.104504  \n",
      "data/bbc/entertainment/001.txt  0.298063  0.159935  0.472831  0.017562  \n",
      "data/bbc/tech/369.txt           0.299356 -0.218140  0.159611 -0.152300  \n",
      "data/bbc/entertainment/269.txt -0.063822  0.031189  0.538759 -0.147875  \n",
      "data/bbc/sport/431.txt          0.190515 -0.011638  0.615259  0.005692  \n",
      "\n",
      "[1490 rows x 1024 columns]\n",
      "data/bbc/business/313.txt         0\n",
      "data/bbc/entertainment/045.txt    1\n",
      "data/bbc/entertainment/197.txt    1\n",
      "data/bbc/sport/100.txt            3\n",
      "data/bbc/sport/378.txt            3\n",
      "                                 ..\n",
      "data/bbc/sport/055.txt            3\n",
      "data/bbc/entertainment/001.txt    1\n",
      "data/bbc/tech/369.txt             4\n",
      "data/bbc/entertainment/269.txt    1\n",
      "data/bbc/sport/431.txt            3\n",
      "Name: 2, Length: 1490, dtype: int64\n",
      "[0.9782312925170068, 0.9782312925170068, 0.9782312925170068, 0.9782312925170068, 0.9782312925170068]\n"
     ]
    }
   ],
   "source": [
    "elmo_accuracies = get_classification_accuracy(\n",
    "    elmo_doc_embeddings, train_labels, test_labels, n_trials=5\n",
    ")\n",
    "print(elmo_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06df915",
   "metadata": {},
   "source": [
    "## Plot the accuracies of different models\n",
    "\n",
    "Here we plot the accuracies from 5 trials, for different algorithms as box plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c3f2383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Skipgram</th>\n",
       "      <th>CBOW</th>\n",
       "      <th>GloVe</th>\n",
       "      <th>ELMo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.880272</td>\n",
       "      <td>0.842177</td>\n",
       "      <td>0.697959</td>\n",
       "      <td>0.978231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.880272</td>\n",
       "      <td>0.842177</td>\n",
       "      <td>0.697959</td>\n",
       "      <td>0.978231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.880272</td>\n",
       "      <td>0.842177</td>\n",
       "      <td>0.697959</td>\n",
       "      <td>0.978231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.880272</td>\n",
       "      <td>0.842177</td>\n",
       "      <td>0.697959</td>\n",
       "      <td>0.978231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.880272</td>\n",
       "      <td>0.842177</td>\n",
       "      <td>0.697959</td>\n",
       "      <td>0.978231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Skipgram      CBOW     GloVe      ELMo\n",
       "0  0.880272  0.842177  0.697959  0.978231\n",
       "1  0.880272  0.842177  0.697959  0.978231\n",
       "2  0.880272  0.842177  0.697959  0.978231\n",
       "3  0.880272  0.842177  0.697959  0.978231\n",
       "4  0.880272  0.842177  0.697959  0.978231"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_df = pd.DataFrame(\n",
    "    np.array([skipgram_accuracies, cbow_accuracies, glove_accuracies, elmo_accuracies]).T,\n",
    "    columns = ['Skipgram', 'CBOW', \"GloVe\", \"ELMo\"]\n",
    ")\n",
    "\n",
    "accuracy_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6499c821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "boxplot = accuracy_df.boxplot(figsize=(10,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aea8a1cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Run Date: Thursday, January 19, 2023\n",
      "# Run Time: 00:00:16\n"
     ]
    }
   ],
   "source": [
    "endTime = time.time()\n",
    "elapsedTime = time.strftime(\"%H:%M:%S\", time.gmtime(endTime - startTime))\n",
    "\n",
    "print(todaysDate.strftime('# Run Date: %A, %B %d, %Y'))\n",
    "print(f\"# Run Time: {elapsedTime}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
