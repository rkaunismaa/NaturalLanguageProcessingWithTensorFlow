{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80799580",
   "metadata": {},
   "source": [
    "## Classifying documents with embeddings\n",
    "\n",
    "<table align=\"left\">\n",
    "    <td>\n",
    "        <a target=\"_blank\" href=\"https://colab.research.google.com/github/thushv89/packt_nlp_tensorflow_2/blob/master/Ch04-Advance-Word-Vectors/ch4_document_classification.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "    </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66cf2460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "%matplotlib inline\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from matplotlib import pylab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975ea2c9",
   "metadata": {},
   "source": [
    "## Downloading the data\n",
    "\n",
    "This code downloads a [BBC dataset](hhttp://mlg.ucd.ie/files/datasets/bbc-fulltext.zip) consisting of news articles published by BBC. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a066561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists\n",
      "bbc-fulltext.zip has already been extracted\n"
     ]
    }
   ],
   "source": [
    "url = 'http://mlg.ucd.ie/files/datasets/bbc-fulltext.zip'\n",
    "\n",
    "\n",
    "def download_data(url, data_dir):\n",
    "    \"\"\"Download a file if not present, and make sure it's the right size.\"\"\"\n",
    "    \n",
    "    # Create the data directory if not exist\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "    file_path = os.path.join(data_dir, 'bbc-fulltext.zip')\n",
    "    \n",
    "    # If file doesnt exist, download\n",
    "    if not os.path.exists(file_path):\n",
    "        print('Downloading file...')\n",
    "        filename, _ = urlretrieve(url, file_path)\n",
    "    else:\n",
    "        print(\"File already exists\")\n",
    "  \n",
    "    extract_path = os.path.join(data_dir, 'bbc')\n",
    "    \n",
    "    # If data has not been extracted already, extract data\n",
    "    if not os.path.exists(extract_path):        \n",
    "        with zipfile.ZipFile(os.path.join(data_dir, 'bbc-fulltext.zip'), 'r') as zipf:\n",
    "            zipf.extractall(data_dir)\n",
    "    else:\n",
    "        print(\"bbc-fulltext.zip has already been extracted\")\n",
    "    \n",
    "download_data(url, 'data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0544e94b",
   "metadata": {},
   "source": [
    "### Read Data\n",
    "\n",
    "Here we read all the files and keep them as a list of strings, where each string is a single article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bc7494c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading files\n",
      "................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................. 401.txt\n",
      "Detected 2225 stories\n",
      "865163 words found in the total news set\n",
      "Example words (start):  Ad sales boost Time Warner profit  Quarterly profi\n",
      "Example words (end):  Online was the game, ahhhh them was the days ! LOL\n"
     ]
    }
   ],
   "source": [
    "def read_data(data_dir):\n",
    "    \n",
    "    # This will contain the full list of stories\n",
    "    news_stories = []    \n",
    "    filenames = []\n",
    "    print(\"Reading files\")\n",
    "    \n",
    "    i = 0 # Just used for printing progress\n",
    "    for root, dirs, files in os.walk(data_dir):\n",
    "        \n",
    "        for fi, f in enumerate(files):\n",
    "            \n",
    "            # We don't read the readme file\n",
    "            if 'readme' in f.lower():\n",
    "                continue\n",
    "            \n",
    "            # Printing progress\n",
    "            i += 1\n",
    "            print(\".\"*i, f, end='\\r')\n",
    "            \n",
    "            # Open the file\n",
    "            with open(os.path.join(root, f), encoding='latin-1') as text_file:\n",
    "                \n",
    "                story = []\n",
    "                # Read all the lines\n",
    "                for row in text_file:\n",
    "                                        \n",
    "                    story.append(row.strip())\n",
    "                    \n",
    "                # Create a single string with all the rows in the doc\n",
    "                story = ' '.join(story)                        \n",
    "                # Add that to the list\n",
    "                news_stories.append(story)  \n",
    "                filenames.append(os.path.join(root, f))\n",
    "                \n",
    "        print('', end='\\r')\n",
    "        \n",
    "    print(f\"\\nDetected {len(news_stories)} stories\")\n",
    "    return news_stories, filenames\n",
    "                \n",
    "  \n",
    "news_stories, filenames = read_data(os.path.join('data', 'bbc'))\n",
    "\n",
    "# Printing some stats and sample data\n",
    "print(f\"{sum([len(story.split(' ')) for story in news_stories])} words found in the total news set\")\n",
    "print('Example words (start): ',news_stories[0][:50])\n",
    "print('Example words (end): ',news_stories[-1][-50:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12298545",
   "metadata": {},
   "source": [
    "## Build a Tokenizer\n",
    "\n",
    "Here we build a tokenizer, that performs simple preprocessing like,\n",
    "\n",
    "* Converting letters to lower case\n",
    "* Removing punctuation\n",
    "\n",
    "and tokenize the strings based on a defined separator. Then each token is converted to an Integer ID, as computers understand numbers, not strings. In the background, the tokenizer builds a word to index dictionary, that defines a unique ID for each word in the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d3405d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data fitted on the tokenizer\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "n_vocab = 15000 + 1\n",
    "tokenizer = Tokenizer(\n",
    "    num_words=n_vocab - 1,\n",
    "    filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "    lower=True, split=' ', oov_token=''\n",
    ")\n",
    "\n",
    "tokenizer.fit_on_texts(news_stories)\n",
    "print(\"Data fitted on the tokenizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6cc22a",
   "metadata": {},
   "source": [
    "## Generate labels for data\n",
    "\n",
    "We generate a label using the filenames to train a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "43c25400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data\\bbc\\business\\001.txt    0\n",
       "data\\bbc\\business\\002.txt    0\n",
       "data\\bbc\\business\\003.txt    0\n",
       "data\\bbc\\business\\004.txt    0\n",
       "data\\bbc\\business\\005.txt    0\n",
       "Name: 2, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_ser = pd.Series(filenames, index=filenames).str.split(os.path.sep, expand=True).iloc[:, -2].map(\n",
    "    {'business': 0, 'entertainment': 1, 'politics': 2, 'sport': 3, 'tech': 4}\n",
    ")\n",
    "labels_ser.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edec0dcc",
   "metadata": {},
   "source": [
    "## Create train/test split\n",
    "\n",
    "Here we use 67% data as training and 33% as testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1876e67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_labels, test_labels = train_test_split(labels_ser, test_size=0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e457b5d1",
   "metadata": {},
   "source": [
    "## Generating document embeddings\n",
    "\n",
    "Here we write a function to generate document embeddings from the previous embedding arrays we saved to the disk for `skip-gram`, `CBOW` and `GloVe` algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0c0967e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_document_embeddings(texts, filenames, tokenizer, embeddings):\n",
    "    \n",
    "    \"\"\" This function takes a sequence of tokens and compute the mean embedding vector \\\n",
    "    from the word vectors of all the tokens in the document \"\"\"\n",
    "    \n",
    "    doc_embedding_df = [] # Contains document embeddings for all the articles\n",
    "    assert isinstance(embeddings, pd.DataFrame), 'embeddings must be a pd.DataFrame'\n",
    "    \n",
    "    # This is a trick we use to quickly get the text preprocessed by the tokenizer\n",
    "    # We first convert text to a sequences, and then back to text, which will give the\n",
    "    # preprocessed tokens\n",
    "    sequences = tokenizer.texts_to_sequences(texts)    \n",
    "    preprocessed_texts = tokenizer.sequences_to_texts(sequences)\n",
    "    \n",
    "    # For each text,\n",
    "    for text in preprocessed_texts:\n",
    "        # Make sure we had matches for tokens in the embedding matrx\n",
    "        assert embeddings.loc[text.split(' '), :].shape[0]>0\n",
    "        # Compute mean of all the embeddings associated with words\n",
    "        mean_embedding = embeddings.loc[text.split(' '), :].mean(axis=0)\n",
    "        # Add that to list\n",
    "        doc_embedding_df.append(mean_embedding)\n",
    "        \n",
    "    # Save the doc embeddings in a dataframe\n",
    "    doc_embedding_df = pd.DataFrame(doc_embedding_df, index=filenames)\n",
    "    \n",
    "    return doc_embedding_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4088f799",
   "metadata": {},
   "source": [
    "## Compute skip-gram based document embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "11760c18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>-1.427625</td>\n",
       "      <td>-1.154279</td>\n",
       "      <td>-1.027655</td>\n",
       "      <td>1.363687</td>\n",
       "      <td>1.353831</td>\n",
       "      <td>-1.211860</td>\n",
       "      <td>1.279560</td>\n",
       "      <td>-1.315888</td>\n",
       "      <td>0.602955</td>\n",
       "      <td>1.220195</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.448210</td>\n",
       "      <td>-1.254843</td>\n",
       "      <td>-0.995438</td>\n",
       "      <td>-1.339593</td>\n",
       "      <td>1.134659</td>\n",
       "      <td>1.427381</td>\n",
       "      <td>1.354307</td>\n",
       "      <td>-1.187261</td>\n",
       "      <td>-1.243143</td>\n",
       "      <td>1.494999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>-0.327097</td>\n",
       "      <td>-0.521317</td>\n",
       "      <td>0.205179</td>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.016888</td>\n",
       "      <td>-0.510694</td>\n",
       "      <td>0.216325</td>\n",
       "      <td>-0.236522</td>\n",
       "      <td>-0.234402</td>\n",
       "      <td>0.096585</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.483350</td>\n",
       "      <td>-0.541382</td>\n",
       "      <td>0.268705</td>\n",
       "      <td>0.125636</td>\n",
       "      <td>0.116332</td>\n",
       "      <td>0.349278</td>\n",
       "      <td>0.036865</td>\n",
       "      <td>0.191476</td>\n",
       "      <td>0.131313</td>\n",
       "      <td>0.323932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>-0.044946</td>\n",
       "      <td>-0.009830</td>\n",
       "      <td>-0.782439</td>\n",
       "      <td>-0.040411</td>\n",
       "      <td>0.141403</td>\n",
       "      <td>-0.141793</td>\n",
       "      <td>-0.206453</td>\n",
       "      <td>-0.166947</td>\n",
       "      <td>-0.143746</td>\n",
       "      <td>0.096245</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.103055</td>\n",
       "      <td>0.063623</td>\n",
       "      <td>0.202459</td>\n",
       "      <td>-0.460181</td>\n",
       "      <td>0.388977</td>\n",
       "      <td>0.098845</td>\n",
       "      <td>0.169221</td>\n",
       "      <td>0.060449</td>\n",
       "      <td>0.167599</td>\n",
       "      <td>0.137362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>-0.097616</td>\n",
       "      <td>-0.028466</td>\n",
       "      <td>0.373821</td>\n",
       "      <td>-0.009577</td>\n",
       "      <td>0.083440</td>\n",
       "      <td>-0.904716</td>\n",
       "      <td>-0.029045</td>\n",
       "      <td>-0.154992</td>\n",
       "      <td>1.113204</td>\n",
       "      <td>-0.057169</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026706</td>\n",
       "      <td>-0.181484</td>\n",
       "      <td>0.122591</td>\n",
       "      <td>-0.298591</td>\n",
       "      <td>-0.099004</td>\n",
       "      <td>-0.004557</td>\n",
       "      <td>-0.004320</td>\n",
       "      <td>0.022960</td>\n",
       "      <td>-0.197245</td>\n",
       "      <td>0.600641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>-0.518225</td>\n",
       "      <td>0.079831</td>\n",
       "      <td>0.218721</td>\n",
       "      <td>0.063918</td>\n",
       "      <td>0.070212</td>\n",
       "      <td>0.149180</td>\n",
       "      <td>-0.034519</td>\n",
       "      <td>0.094533</td>\n",
       "      <td>-0.077960</td>\n",
       "      <td>0.268403</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.827636</td>\n",
       "      <td>-0.024029</td>\n",
       "      <td>-1.102254</td>\n",
       "      <td>-0.748013</td>\n",
       "      <td>1.626101</td>\n",
       "      <td>0.077321</td>\n",
       "      <td>-0.022681</td>\n",
       "      <td>-0.401835</td>\n",
       "      <td>-0.025986</td>\n",
       "      <td>0.779170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>-0.380675</td>\n",
       "      <td>-0.060902</td>\n",
       "      <td>0.467516</td>\n",
       "      <td>0.039847</td>\n",
       "      <td>-0.072255</td>\n",
       "      <td>-0.297857</td>\n",
       "      <td>0.486448</td>\n",
       "      <td>-0.153416</td>\n",
       "      <td>-0.105748</td>\n",
       "      <td>0.062139</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.224600</td>\n",
       "      <td>0.237030</td>\n",
       "      <td>0.147239</td>\n",
       "      <td>-0.390464</td>\n",
       "      <td>-0.542171</td>\n",
       "      <td>0.237066</td>\n",
       "      <td>0.244738</td>\n",
       "      <td>0.113206</td>\n",
       "      <td>0.120161</td>\n",
       "      <td>0.542526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>-0.281075</td>\n",
       "      <td>-0.091397</td>\n",
       "      <td>0.542255</td>\n",
       "      <td>0.244439</td>\n",
       "      <td>0.282127</td>\n",
       "      <td>0.126421</td>\n",
       "      <td>0.394537</td>\n",
       "      <td>-0.483896</td>\n",
       "      <td>2.149094</td>\n",
       "      <td>0.366463</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.297622</td>\n",
       "      <td>0.075509</td>\n",
       "      <td>0.131862</td>\n",
       "      <td>-0.245451</td>\n",
       "      <td>-0.061112</td>\n",
       "      <td>0.233343</td>\n",
       "      <td>0.208846</td>\n",
       "      <td>0.145481</td>\n",
       "      <td>0.015640</td>\n",
       "      <td>0.244263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>-0.658752</td>\n",
       "      <td>-0.482500</td>\n",
       "      <td>0.311281</td>\n",
       "      <td>-0.085630</td>\n",
       "      <td>-0.255787</td>\n",
       "      <td>0.268496</td>\n",
       "      <td>0.084899</td>\n",
       "      <td>0.272683</td>\n",
       "      <td>1.179264</td>\n",
       "      <td>0.066926</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051931</td>\n",
       "      <td>-0.338828</td>\n",
       "      <td>-0.167985</td>\n",
       "      <td>0.386470</td>\n",
       "      <td>1.433977</td>\n",
       "      <td>-0.077181</td>\n",
       "      <td>0.968448</td>\n",
       "      <td>0.411699</td>\n",
       "      <td>-0.514699</td>\n",
       "      <td>0.242268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>for</th>\n",
       "      <td>-0.318278</td>\n",
       "      <td>0.152649</td>\n",
       "      <td>0.146557</td>\n",
       "      <td>0.309478</td>\n",
       "      <td>-0.197440</td>\n",
       "      <td>0.130187</td>\n",
       "      <td>-0.253964</td>\n",
       "      <td>-0.341225</td>\n",
       "      <td>1.062025</td>\n",
       "      <td>0.092227</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.129353</td>\n",
       "      <td>-0.245434</td>\n",
       "      <td>-0.024825</td>\n",
       "      <td>0.148060</td>\n",
       "      <td>0.515092</td>\n",
       "      <td>0.760889</td>\n",
       "      <td>0.231376</td>\n",
       "      <td>0.088485</td>\n",
       "      <td>-0.387053</td>\n",
       "      <td>-0.181140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>-0.215979</td>\n",
       "      <td>0.173202</td>\n",
       "      <td>-0.759992</td>\n",
       "      <td>0.860715</td>\n",
       "      <td>0.550769</td>\n",
       "      <td>0.034918</td>\n",
       "      <td>0.289527</td>\n",
       "      <td>-0.661340</td>\n",
       "      <td>-0.389477</td>\n",
       "      <td>1.165248</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.350128</td>\n",
       "      <td>0.061945</td>\n",
       "      <td>0.086671</td>\n",
       "      <td>0.178867</td>\n",
       "      <td>1.337760</td>\n",
       "      <td>0.410331</td>\n",
       "      <td>0.439239</td>\n",
       "      <td>0.141097</td>\n",
       "      <td>0.037151</td>\n",
       "      <td>0.528937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 128 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6    \\\n",
       "NaN -1.427625 -1.154279 -1.027655  1.363687  1.353831 -1.211860  1.279560   \n",
       "    -0.327097 -0.521317  0.205179 -0.177167  0.016888 -0.510694  0.216325   \n",
       "the -0.044946 -0.009830 -0.782439 -0.040411  0.141403 -0.141793 -0.206453   \n",
       "to  -0.097616 -0.028466  0.373821 -0.009577  0.083440 -0.904716 -0.029045   \n",
       "of  -0.518225  0.079831  0.218721  0.063918  0.070212  0.149180 -0.034519   \n",
       "and -0.380675 -0.060902  0.467516  0.039847 -0.072255 -0.297857  0.486448   \n",
       "a   -0.281075 -0.091397  0.542255  0.244439  0.282127  0.126421  0.394537   \n",
       "in  -0.658752 -0.482500  0.311281 -0.085630 -0.255787  0.268496  0.084899   \n",
       "for -0.318278  0.152649  0.146557  0.309478 -0.197440  0.130187 -0.253964   \n",
       "is  -0.215979  0.173202 -0.759992  0.860715  0.550769  0.034918  0.289527   \n",
       "\n",
       "          7         8         9    ...       118       119       120  \\\n",
       "NaN -1.315888  0.602955  1.220195  ... -1.448210 -1.254843 -0.995438   \n",
       "    -0.236522 -0.234402  0.096585  ... -0.483350 -0.541382  0.268705   \n",
       "the -0.166947 -0.143746  0.096245  ... -0.103055  0.063623  0.202459   \n",
       "to  -0.154992  1.113204 -0.057169  ...  0.026706 -0.181484  0.122591   \n",
       "of   0.094533 -0.077960  0.268403  ... -0.827636 -0.024029 -1.102254   \n",
       "and -0.153416 -0.105748  0.062139  ... -0.224600  0.237030  0.147239   \n",
       "a   -0.483896  2.149094  0.366463  ... -0.297622  0.075509  0.131862   \n",
       "in   0.272683  1.179264  0.066926  ...  0.051931 -0.338828 -0.167985   \n",
       "for -0.341225  1.062025  0.092227  ... -0.129353 -0.245434 -0.024825   \n",
       "is  -0.661340 -0.389477  1.165248  ... -0.350128  0.061945  0.086671   \n",
       "\n",
       "          121       122       123       124       125       126       127  \n",
       "NaN -1.339593  1.134659  1.427381  1.354307 -1.187261 -1.243143  1.494999  \n",
       "     0.125636  0.116332  0.349278  0.036865  0.191476  0.131313  0.323932  \n",
       "the -0.460181  0.388977  0.098845  0.169221  0.060449  0.167599  0.137362  \n",
       "to  -0.298591 -0.099004 -0.004557 -0.004320  0.022960 -0.197245  0.600641  \n",
       "of  -0.748013  1.626101  0.077321 -0.022681 -0.401835 -0.025986  0.779170  \n",
       "and -0.390464 -0.542171  0.237066  0.244738  0.113206  0.120161  0.542526  \n",
       "a   -0.245451 -0.061112  0.233343  0.208846  0.145481  0.015640  0.244263  \n",
       "in   0.386470  1.433977 -0.077181  0.968448  0.411699 -0.514699  0.242268  \n",
       "for  0.148060  0.515092  0.760889  0.231376  0.088485 -0.387053 -0.181140  \n",
       "is   0.178867  1.337760  0.410331  0.439239  0.141097  0.037151  0.528937  \n",
       "\n",
       "[10 rows x 128 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the skip-gram embeddings context and target\n",
    "skipgram_context_embeddings = pd.read_pickle(\n",
    "    os.path.join('../Ch03-Word-Vectors/skipgram_embeddings', 'context_embedding.pkl')\n",
    ")\n",
    "skipgram_target_embeddings = pd.read_pickle(\n",
    "    os.path.join('../Ch03-Word-Vectors/skipgram_embeddings', 'target_embedding.pkl')\n",
    ")\n",
    "skipgram_context_embeddings.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8508fcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the mean of context & target embeddings for better embeddings\n",
    "skipgram_embeddings = (skipgram_context_embeddings + skipgram_target_embeddings)/2\n",
    "# Generate the document embeddings with the average context target embeddings\n",
    "skipgram_doc_embeddings = generate_document_embeddings(news_stories, filenames, tokenizer, skipgram_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29543a4",
   "metadata": {},
   "source": [
    "## Train a document classifier\n",
    "\n",
    "Here we train a simple document classifier, using document embeddings as inputs and labels we generated as targets. To get a consistent measure, we will run several trials.\n",
    "\n",
    "---\n",
    "*Document classifier*\n",
    "\n",
    "![Document classifier](notebook_images/04_06.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "25b3ba1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     0         1         2         3    \\\n",
      "data\\bbc\\entertainment\\248.txt -0.045643 -0.048086 -0.064579  0.031135   \n",
      "data\\bbc\\entertainment\\079.txt -0.069688 -0.057638 -0.104164  0.031376   \n",
      "data\\bbc\\business\\202.txt      -0.045332 -0.089156 -0.039038  0.051979   \n",
      "data\\bbc\\politics\\068.txt      -0.039209 -0.055415 -0.105889  0.047598   \n",
      "data\\bbc\\sport\\136.txt         -0.017236 -0.059328 -0.098621 -0.006659   \n",
      "...                                  ...       ...       ...       ...   \n",
      "data\\bbc\\entertainment\\201.txt -0.063080 -0.069308 -0.084830  0.053150   \n",
      "data\\bbc\\tech\\036.txt          -0.019206 -0.086118 -0.050809  0.074130   \n",
      "data\\bbc\\entertainment\\153.txt -0.070858 -0.068184 -0.065458  0.038598   \n",
      "data\\bbc\\tech\\137.txt          -0.060139 -0.065518 -0.065017  0.062962   \n",
      "data\\bbc\\entertainment\\310.txt -0.051586 -0.092731 -0.105666  0.042580   \n",
      "\n",
      "                                     4         5         6         7    \\\n",
      "data\\bbc\\entertainment\\248.txt  0.047300 -0.070640  0.057771 -0.064438   \n",
      "data\\bbc\\entertainment\\079.txt  0.094109 -0.008788  0.056727 -0.071088   \n",
      "data\\bbc\\business\\202.txt       0.044783 -0.038648  0.013491 -0.080785   \n",
      "data\\bbc\\politics\\068.txt       0.029354 -0.075120  0.053462 -0.041826   \n",
      "data\\bbc\\sport\\136.txt          0.019134 -0.093042  0.037151 -0.044245   \n",
      "...                                  ...       ...       ...       ...   \n",
      "data\\bbc\\entertainment\\201.txt  0.065222 -0.021572  0.089002 -0.068954   \n",
      "data\\bbc\\tech\\036.txt           0.078010 -0.050393  0.054991 -0.072690   \n",
      "data\\bbc\\entertainment\\153.txt  0.060695 -0.046974  0.073331 -0.073906   \n",
      "data\\bbc\\tech\\137.txt           0.002392 -0.075302  0.063596 -0.078701   \n",
      "data\\bbc\\entertainment\\310.txt  0.051986  0.008804  0.037715 -0.044745   \n",
      "\n",
      "                                     8         9    ...       118       119  \\\n",
      "data\\bbc\\entertainment\\248.txt  0.072099  0.045046  ... -0.054311 -0.023801   \n",
      "data\\bbc\\entertainment\\079.txt  0.000642 -0.009936  ... -0.084915 -0.079617   \n",
      "data\\bbc\\business\\202.txt       0.090839  0.044057  ... -0.046204 -0.027917   \n",
      "data\\bbc\\politics\\068.txt       0.072623  0.060187  ... -0.079377 -0.019705   \n",
      "data\\bbc\\sport\\136.txt          0.099139  0.052466  ... -0.055351 -0.075744   \n",
      "...                                  ...       ...  ...       ...       ...   \n",
      "data\\bbc\\entertainment\\201.txt  0.046063  0.043498  ... -0.089791 -0.081345   \n",
      "data\\bbc\\tech\\036.txt           0.077116  0.082827  ... -0.056621  0.024026   \n",
      "data\\bbc\\entertainment\\153.txt  0.015517  0.023098  ... -0.054828 -0.069613   \n",
      "data\\bbc\\tech\\137.txt           0.111569  0.127722  ... -0.060955 -0.002615   \n",
      "data\\bbc\\entertainment\\310.txt  0.096919  0.046349  ... -0.081535 -0.070336   \n",
      "\n",
      "                                     120       121       122       123  \\\n",
      "data\\bbc\\entertainment\\248.txt -0.029147 -0.084386  0.059451  0.049606   \n",
      "data\\bbc\\entertainment\\079.txt -0.054967 -0.072191  0.116308  0.063350   \n",
      "data\\bbc\\business\\202.txt      -0.055875 -0.108327  0.072546  0.049410   \n",
      "data\\bbc\\politics\\068.txt      -0.039136 -0.093108  0.036586  0.060407   \n",
      "data\\bbc\\sport\\136.txt         -0.032442 -0.086640  0.042917  0.058143   \n",
      "...                                  ...       ...       ...       ...   \n",
      "data\\bbc\\entertainment\\201.txt -0.048635 -0.058650  0.078694  0.071894   \n",
      "data\\bbc\\tech\\036.txt          -0.009712 -0.080647  0.020934  0.025780   \n",
      "data\\bbc\\entertainment\\153.txt -0.063552 -0.056130  0.096009  0.078724   \n",
      "data\\bbc\\tech\\137.txt          -0.074196 -0.108662  0.076213  0.049756   \n",
      "data\\bbc\\entertainment\\310.txt -0.047310 -0.071648  0.112284  0.050276   \n",
      "\n",
      "                                     124       125       126       127  \n",
      "data\\bbc\\entertainment\\248.txt  0.051323 -0.021994 -0.087349  0.073269  \n",
      "data\\bbc\\entertainment\\079.txt  0.118138 -0.055541 -0.025906  0.073121  \n",
      "data\\bbc\\business\\202.txt       0.045191 -0.040061 -0.080207  0.074307  \n",
      "data\\bbc\\politics\\068.txt       0.014668 -0.032048 -0.075154  0.061661  \n",
      "data\\bbc\\sport\\136.txt          0.019601 -0.035825 -0.070020  0.051292  \n",
      "...                                  ...       ...       ...       ...  \n",
      "data\\bbc\\entertainment\\201.txt  0.120080 -0.076017 -0.005843  0.046415  \n",
      "data\\bbc\\tech\\036.txt           0.028722 -0.023980 -0.104199  0.067023  \n",
      "data\\bbc\\entertainment\\153.txt  0.117705 -0.049790 -0.065261  0.056233  \n",
      "data\\bbc\\tech\\137.txt           0.047684 -0.013019 -0.092120  0.059673  \n",
      "data\\bbc\\entertainment\\310.txt  0.086676 -0.053508 -0.033976  0.050210  \n",
      "\n",
      "[1490 rows x 128 columns]\n",
      "data\\bbc\\entertainment\\248.txt    1\n",
      "data\\bbc\\entertainment\\079.txt    1\n",
      "data\\bbc\\business\\202.txt         0\n",
      "data\\bbc\\politics\\068.txt         2\n",
      "data\\bbc\\sport\\136.txt            3\n",
      "                                 ..\n",
      "data\\bbc\\entertainment\\201.txt    1\n",
      "data\\bbc\\tech\\036.txt             4\n",
      "data\\bbc\\entertainment\\153.txt    1\n",
      "data\\bbc\\tech\\137.txt             4\n",
      "data\\bbc\\entertainment\\310.txt    1\n",
      "Name: 2, Length: 1490, dtype: int32\n",
      "Skip-gram accuracies: [0.8517006802721089, 0.8517006802721089, 0.8517006802721089, 0.8517006802721089, 0.8517006802721089]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def get_classification_accuracy(doc_embeddings, train_labels, test_labels, n_trials):\n",
    "    \"\"\" Train a simple MLP model for several trials and measure test accuracy\"\"\"\n",
    "    \n",
    "    accuracies = [] # Store accuracies across trials\n",
    "    \n",
    "    print(doc_embeddings.loc[train_labels.index])\n",
    "    print(train_labels.astype('int'))\n",
    "    # For each trial\n",
    "    for trial in range(n_trials):\n",
    "        # Create a MLP classifier\n",
    "        lr_classifier = LogisticRegression(multi_class='multinomial', max_iter=500)\n",
    "        \n",
    "        # Fit the model on training data\n",
    "        lr_classifier.fit(doc_embeddings.loc[train_labels.index], train_labels)\n",
    "        \n",
    "        # Get the predictions for test data\n",
    "        predictions = lr_classifier.predict(doc_embeddings.loc[test_labels.index])\n",
    "    \n",
    "        # Compute accuracy\n",
    "        accuracies.append(accuracy_score(predictions, test_labels))\n",
    "    \n",
    "    return accuracies\n",
    "\n",
    "# Get classification accuracy for skip-gram models\n",
    "skipgram_accuracies = get_classification_accuracy(\n",
    "    skipgram_doc_embeddings, train_labels.astype('int'), test_labels.astype('int'), n_trials=5\n",
    ")\n",
    "\n",
    "print(f\"Skip-gram accuracies: {skipgram_accuracies}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3aec63b",
   "metadata": {},
   "source": [
    "## Train a classifier on CBOW based document embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1eeb9bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cbow_context_embeddings = pd.read_pickle(\n",
    "    os.path.join('../Ch03-Word-Vectors/cbow_embeddings', 'context_embedding.pkl')\n",
    ")\n",
    "cbow_target_embeddings = pd.read_pickle(\n",
    "    os.path.join('../Ch03-Word-Vectors/cbow_embeddings', 'target_embedding.pkl')\n",
    ")\n",
    "\n",
    "cbow_embeddings = (cbow_context_embeddings + cbow_target_embeddings)/2\n",
    "cbow_doc_embeddings = generate_document_embeddings(news_stories, filenames, tokenizer, cbow_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bf065086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     0         1         2         3    \\\n",
      "data\\bbc\\entertainment\\248.txt  0.071781  0.082947  0.095572 -0.079323   \n",
      "data\\bbc\\entertainment\\079.txt  0.044884  0.094873  0.047027 -0.025499   \n",
      "data\\bbc\\business\\202.txt       0.038276  0.059557  0.084361 -0.051599   \n",
      "data\\bbc\\politics\\068.txt       0.083443  0.092401  0.149390 -0.094661   \n",
      "data\\bbc\\sport\\136.txt          0.082194  0.080269  0.110319 -0.095240   \n",
      "...                                  ...       ...       ...       ...   \n",
      "data\\bbc\\entertainment\\201.txt  0.024920  0.094388  0.028734 -0.051324   \n",
      "data\\bbc\\tech\\036.txt           0.037486  0.102186  0.129274 -0.063333   \n",
      "data\\bbc\\entertainment\\153.txt  0.059731  0.081208  0.039262 -0.063446   \n",
      "data\\bbc\\tech\\137.txt           0.076265  0.087235  0.173699 -0.104362   \n",
      "data\\bbc\\entertainment\\310.txt  0.044831  0.096241  0.112403 -0.080002   \n",
      "\n",
      "                                     4         5         6         7    \\\n",
      "data\\bbc\\entertainment\\248.txt -0.069191 -0.058489  0.076083 -0.060113   \n",
      "data\\bbc\\entertainment\\079.txt -0.102025 -0.062813  0.060256 -0.081352   \n",
      "data\\bbc\\business\\202.txt      -0.043765 -0.047690  0.067194 -0.057156   \n",
      "data\\bbc\\politics\\068.txt      -0.059204 -0.079006  0.064691 -0.055327   \n",
      "data\\bbc\\sport\\136.txt         -0.071001 -0.078128  0.087279 -0.040389   \n",
      "...                                  ...       ...       ...       ...   \n",
      "data\\bbc\\entertainment\\201.txt -0.103338 -0.064473  0.076702 -0.034115   \n",
      "data\\bbc\\tech\\036.txt          -0.048991 -0.087123  0.067690 -0.065899   \n",
      "data\\bbc\\entertainment\\153.txt -0.078985 -0.074001  0.089299 -0.024914   \n",
      "data\\bbc\\tech\\137.txt          -0.050471 -0.083983  0.081381 -0.051429   \n",
      "data\\bbc\\entertainment\\310.txt -0.085901 -0.074819  0.074127 -0.054671   \n",
      "\n",
      "                                     8         9    ...       118       119  \\\n",
      "data\\bbc\\entertainment\\248.txt -0.076311 -0.088080  ...  0.078303  0.083989   \n",
      "data\\bbc\\entertainment\\079.txt -0.086974 -0.091283  ...  0.056957  0.087402   \n",
      "data\\bbc\\business\\202.txt      -0.086033 -0.061083  ...  0.064729  0.053694   \n",
      "data\\bbc\\politics\\068.txt      -0.094037 -0.082261  ...  0.074801  0.058108   \n",
      "data\\bbc\\sport\\136.txt         -0.093487 -0.063449  ...  0.085996  0.052517   \n",
      "...                                  ...       ...  ...       ...       ...   \n",
      "data\\bbc\\entertainment\\201.txt -0.075556 -0.088731  ...  0.037870  0.061996   \n",
      "data\\bbc\\tech\\036.txt          -0.086699 -0.102825  ...  0.055525  0.057990   \n",
      "data\\bbc\\entertainment\\153.txt -0.068470 -0.066587  ...  0.065078  0.063877   \n",
      "data\\bbc\\tech\\137.txt          -0.097551 -0.098745  ...  0.069037  0.060151   \n",
      "data\\bbc\\entertainment\\310.txt -0.112266 -0.097633  ...  0.064012  0.074112   \n",
      "\n",
      "                                     120       121       122       123  \\\n",
      "data\\bbc\\entertainment\\248.txt  0.078679  0.093254 -0.074837 -0.076579   \n",
      "data\\bbc\\entertainment\\079.txt  0.058808  0.039932 -0.076683 -0.039715   \n",
      "data\\bbc\\business\\202.txt       0.090222  0.087272 -0.092829 -0.062971   \n",
      "data\\bbc\\politics\\068.txt       0.076672  0.118753 -0.080304 -0.083551   \n",
      "data\\bbc\\sport\\136.txt          0.079272  0.152048 -0.073213 -0.066209   \n",
      "...                                  ...       ...       ...       ...   \n",
      "data\\bbc\\entertainment\\201.txt  0.052601  0.046694 -0.067649 -0.044185   \n",
      "data\\bbc\\tech\\036.txt           0.069411  0.072096 -0.100830 -0.101612   \n",
      "data\\bbc\\entertainment\\153.txt  0.062766  0.056165 -0.083212 -0.051810   \n",
      "data\\bbc\\tech\\137.txt           0.109852  0.112290 -0.102411 -0.103344   \n",
      "data\\bbc\\entertainment\\310.txt  0.101179  0.113371 -0.093746 -0.056834   \n",
      "\n",
      "                                     124       125       126       127  \n",
      "data\\bbc\\entertainment\\248.txt -0.089810 -0.075622 -0.108121  0.077003  \n",
      "data\\bbc\\entertainment\\079.txt -0.049539 -0.108964 -0.031357  0.047605  \n",
      "data\\bbc\\business\\202.txt      -0.090268 -0.050044 -0.059606  0.085474  \n",
      "data\\bbc\\politics\\068.txt      -0.091086 -0.092453 -0.115159  0.079777  \n",
      "data\\bbc\\sport\\136.txt         -0.095673 -0.089731 -0.122981  0.090343  \n",
      "...                                  ...       ...       ...       ...  \n",
      "data\\bbc\\entertainment\\201.txt -0.045824 -0.093723 -0.016751  0.066952  \n",
      "data\\bbc\\tech\\036.txt          -0.080841 -0.066269 -0.088050  0.101979  \n",
      "data\\bbc\\entertainment\\153.txt -0.070254 -0.077007 -0.044301  0.045300  \n",
      "data\\bbc\\tech\\137.txt          -0.088889 -0.065394 -0.106931  0.082958  \n",
      "data\\bbc\\entertainment\\310.txt -0.075470 -0.123233 -0.058433  0.113496  \n",
      "\n",
      "[1490 rows x 128 columns]\n",
      "data\\bbc\\entertainment\\248.txt    1\n",
      "data\\bbc\\entertainment\\079.txt    1\n",
      "data\\bbc\\business\\202.txt         0\n",
      "data\\bbc\\politics\\068.txt         2\n",
      "data\\bbc\\sport\\136.txt            3\n",
      "                                 ..\n",
      "data\\bbc\\entertainment\\201.txt    1\n",
      "data\\bbc\\tech\\036.txt             4\n",
      "data\\bbc\\entertainment\\153.txt    1\n",
      "data\\bbc\\tech\\137.txt             4\n",
      "data\\bbc\\entertainment\\310.txt    1\n",
      "Name: 2, Length: 1490, dtype: int32\n",
      "[0.8013605442176871, 0.8013605442176871, 0.8013605442176871, 0.8013605442176871, 0.8013605442176871]\n"
     ]
    }
   ],
   "source": [
    "cbow_accuracies = get_classification_accuracy(\n",
    "    cbow_doc_embeddings, train_labels, test_labels, n_trials=5\n",
    ")\n",
    "print(cbow_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14000a4d",
   "metadata": {},
   "source": [
    "## Train a classifier on GloVe embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e383884c",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_context_embeddings = pd.read_pickle(\n",
    "    os.path.join('glove_embeddings', 'context_embedding_and_bias.pkl')\n",
    ")\n",
    "glove_target_embeddings = pd.read_pickle(\n",
    "    os.path.join('glove_embeddings', 'target_embedding_and_bias.pkl')\n",
    ")\n",
    "\n",
    "glove_embeddings = (glove_context_embeddings.iloc[:, :-1] + glove_target_embeddings.iloc[:, :-1])/2\n",
    "glove_doc_embeddings = generate_document_embeddings(news_stories, filenames, tokenizer, glove_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "584e58b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     0         1         2         3    \\\n",
      "data\\bbc\\entertainment\\248.txt -0.069322  0.109426  0.049055  0.060233   \n",
      "data\\bbc\\entertainment\\079.txt -0.043235  0.116852  0.089938  0.087927   \n",
      "data\\bbc\\business\\202.txt      -0.043511  0.120297  0.075639  0.059141   \n",
      "data\\bbc\\politics\\068.txt      -0.049546  0.105965  0.034564  0.054483   \n",
      "data\\bbc\\sport\\136.txt         -0.087594  0.115590  0.044769  0.040296   \n",
      "...                                  ...       ...       ...       ...   \n",
      "data\\bbc\\entertainment\\201.txt -0.036807  0.104371  0.089491  0.080431   \n",
      "data\\bbc\\tech\\036.txt          -0.049918  0.110480  0.062690  0.063807   \n",
      "data\\bbc\\entertainment\\153.txt -0.042266  0.096499  0.071240  0.070713   \n",
      "data\\bbc\\tech\\137.txt          -0.046503  0.113023  0.039012  0.055099   \n",
      "data\\bbc\\entertainment\\310.txt -0.052142  0.128655  0.060866  0.081726   \n",
      "\n",
      "                                     4         5         6         7    \\\n",
      "data\\bbc\\entertainment\\248.txt  0.131788 -0.065599 -0.073839  0.110318   \n",
      "data\\bbc\\entertainment\\079.txt  0.141919 -0.094794 -0.029311  0.134814   \n",
      "data\\bbc\\business\\202.txt       0.128630 -0.060180 -0.057705  0.088445   \n",
      "data\\bbc\\politics\\068.txt       0.135131 -0.072016 -0.066390  0.107994   \n",
      "data\\bbc\\sport\\136.txt          0.147596 -0.077686 -0.080453  0.101464   \n",
      "...                                  ...       ...       ...       ...   \n",
      "data\\bbc\\entertainment\\201.txt  0.144325 -0.090330 -0.054044  0.124868   \n",
      "data\\bbc\\tech\\036.txt           0.145189 -0.081208 -0.056413  0.087104   \n",
      "data\\bbc\\entertainment\\153.txt  0.127375 -0.080546 -0.059931  0.118630   \n",
      "data\\bbc\\tech\\137.txt           0.138907 -0.076418 -0.079564  0.099789   \n",
      "data\\bbc\\entertainment\\310.txt  0.136316 -0.100881 -0.045305  0.134008   \n",
      "\n",
      "                                     8         9    ...       118       119  \\\n",
      "data\\bbc\\entertainment\\248.txt -0.014581 -0.130740  ...  0.126327 -0.020295   \n",
      "data\\bbc\\entertainment\\079.txt -0.003118 -0.115862  ...  0.121450 -0.040553   \n",
      "data\\bbc\\business\\202.txt       0.004434 -0.115177  ...  0.122319 -0.024958   \n",
      "data\\bbc\\politics\\068.txt      -0.015573 -0.125360  ...  0.128955 -0.018513   \n",
      "data\\bbc\\sport\\136.txt         -0.008495 -0.123973  ...  0.126671 -0.021014   \n",
      "...                                  ...       ...  ...       ...       ...   \n",
      "data\\bbc\\entertainment\\201.txt -0.010269 -0.110966  ...  0.116522 -0.039805   \n",
      "data\\bbc\\tech\\036.txt          -0.028284 -0.120910  ...  0.116213 -0.028523   \n",
      "data\\bbc\\entertainment\\153.txt -0.025231 -0.125845  ...  0.112483 -0.040171   \n",
      "data\\bbc\\tech\\137.txt          -0.028929 -0.140506  ...  0.120665 -0.024811   \n",
      "data\\bbc\\entertainment\\310.txt -0.022226 -0.127927  ...  0.128393 -0.027718   \n",
      "\n",
      "                                     120       121       122       123  \\\n",
      "data\\bbc\\entertainment\\248.txt -0.165380  0.023775  0.018533 -0.171334   \n",
      "data\\bbc\\entertainment\\079.txt -0.181949  0.076953 -0.011051 -0.168521   \n",
      "data\\bbc\\business\\202.txt      -0.168286  0.031190  0.014502 -0.157518   \n",
      "data\\bbc\\politics\\068.txt      -0.155918  0.015813  0.011782 -0.171288   \n",
      "data\\bbc\\sport\\136.txt         -0.168707  0.009842  0.008973 -0.186938   \n",
      "...                                  ...       ...       ...       ...   \n",
      "data\\bbc\\entertainment\\201.txt -0.162618  0.068422  0.002843 -0.150549   \n",
      "data\\bbc\\tech\\036.txt          -0.172507  0.036183  0.058543 -0.171576   \n",
      "data\\bbc\\entertainment\\153.txt -0.156865  0.045204 -0.006594 -0.156428   \n",
      "data\\bbc\\tech\\137.txt          -0.173747  0.010005  0.040011 -0.173855   \n",
      "data\\bbc\\entertainment\\310.txt -0.184767  0.056676  0.022794 -0.174113   \n",
      "\n",
      "                                     124       125       126       127  \n",
      "data\\bbc\\entertainment\\248.txt  0.025244 -0.090554 -0.062671  0.141100  \n",
      "data\\bbc\\entertainment\\079.txt  0.066853 -0.082966 -0.061987  0.151344  \n",
      "data\\bbc\\business\\202.txt       0.030383 -0.082833 -0.073010  0.148848  \n",
      "data\\bbc\\politics\\068.txt       0.006532 -0.103031 -0.067094  0.161458  \n",
      "data\\bbc\\sport\\136.txt          0.012918 -0.100105 -0.086021  0.157089  \n",
      "...                                  ...       ...       ...       ...  \n",
      "data\\bbc\\entertainment\\201.txt  0.047987 -0.076128 -0.058266  0.144158  \n",
      "data\\bbc\\tech\\036.txt          -0.005716 -0.105813 -0.077115  0.163251  \n",
      "data\\bbc\\entertainment\\153.txt  0.044589 -0.069307 -0.056255  0.135015  \n",
      "data\\bbc\\tech\\137.txt           0.002542 -0.101674 -0.069851  0.165951  \n",
      "data\\bbc\\entertainment\\310.txt  0.049535 -0.096295 -0.059451  0.168806  \n",
      "\n",
      "[1490 rows x 128 columns]\n",
      "data\\bbc\\entertainment\\248.txt    1\n",
      "data\\bbc\\entertainment\\079.txt    1\n",
      "data\\bbc\\business\\202.txt         0\n",
      "data\\bbc\\politics\\068.txt         2\n",
      "data\\bbc\\sport\\136.txt            3\n",
      "                                 ..\n",
      "data\\bbc\\entertainment\\201.txt    1\n",
      "data\\bbc\\tech\\036.txt             4\n",
      "data\\bbc\\entertainment\\153.txt    1\n",
      "data\\bbc\\tech\\137.txt             4\n",
      "data\\bbc\\entertainment\\310.txt    1\n",
      "Name: 2, Length: 1490, dtype: int32\n",
      "[0.6639455782312925, 0.6639455782312925, 0.6639455782312925, 0.6639455782312925, 0.6639455782312925]\n"
     ]
    }
   ],
   "source": [
    "glove_accuracies = get_classification_accuracy(\n",
    "    glove_doc_embeddings, train_labels, test_labels, n_trials=5\n",
    ")\n",
    "print(glove_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193f8174",
   "metadata": {},
   "source": [
    "## Train a classifier on ELMo document embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1973783f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1014</th>\n",
       "      <th>1015</th>\n",
       "      <th>1016</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>1023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>data\\bbc\\readme.txt</th>\n",
       "      <td>0.317657</td>\n",
       "      <td>-0.037904</td>\n",
       "      <td>0.096557</td>\n",
       "      <td>-0.120920</td>\n",
       "      <td>-0.031368</td>\n",
       "      <td>0.100202</td>\n",
       "      <td>-0.026247</td>\n",
       "      <td>0.396833</td>\n",
       "      <td>-0.147786</td>\n",
       "      <td>-0.080523</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.287333</td>\n",
       "      <td>0.232494</td>\n",
       "      <td>0.078371</td>\n",
       "      <td>0.287477</td>\n",
       "      <td>0.104193</td>\n",
       "      <td>0.087736</td>\n",
       "      <td>0.313276</td>\n",
       "      <td>-0.105956</td>\n",
       "      <td>0.213654</td>\n",
       "      <td>0.086695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data\\bbc\\business\\001.txt</th>\n",
       "      <td>0.052209</td>\n",
       "      <td>-0.108837</td>\n",
       "      <td>0.103078</td>\n",
       "      <td>0.060255</td>\n",
       "      <td>0.277382</td>\n",
       "      <td>0.101622</td>\n",
       "      <td>0.147006</td>\n",
       "      <td>0.390242</td>\n",
       "      <td>0.053942</td>\n",
       "      <td>-0.051409</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.179657</td>\n",
       "      <td>0.053069</td>\n",
       "      <td>0.091880</td>\n",
       "      <td>0.257571</td>\n",
       "      <td>0.044403</td>\n",
       "      <td>-0.093912</td>\n",
       "      <td>0.032205</td>\n",
       "      <td>-0.116896</td>\n",
       "      <td>0.420686</td>\n",
       "      <td>0.049002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data\\bbc\\business\\002.txt</th>\n",
       "      <td>-0.277251</td>\n",
       "      <td>-0.498861</td>\n",
       "      <td>-0.000488</td>\n",
       "      <td>0.090846</td>\n",
       "      <td>0.320750</td>\n",
       "      <td>-0.054692</td>\n",
       "      <td>-0.041421</td>\n",
       "      <td>0.329660</td>\n",
       "      <td>-0.438261</td>\n",
       "      <td>-0.232513</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.140432</td>\n",
       "      <td>-0.022603</td>\n",
       "      <td>0.369779</td>\n",
       "      <td>0.214081</td>\n",
       "      <td>-0.019910</td>\n",
       "      <td>-0.004382</td>\n",
       "      <td>-0.073545</td>\n",
       "      <td>0.050382</td>\n",
       "      <td>0.697808</td>\n",
       "      <td>-0.038186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data\\bbc\\business\\003.txt</th>\n",
       "      <td>0.001640</td>\n",
       "      <td>-0.078992</td>\n",
       "      <td>0.178254</td>\n",
       "      <td>-0.076050</td>\n",
       "      <td>-0.188926</td>\n",
       "      <td>0.156753</td>\n",
       "      <td>-0.178013</td>\n",
       "      <td>0.316145</td>\n",
       "      <td>0.339274</td>\n",
       "      <td>0.103716</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077891</td>\n",
       "      <td>0.137827</td>\n",
       "      <td>0.199895</td>\n",
       "      <td>-0.000208</td>\n",
       "      <td>0.204819</td>\n",
       "      <td>-0.148592</td>\n",
       "      <td>0.030815</td>\n",
       "      <td>-0.008611</td>\n",
       "      <td>0.582661</td>\n",
       "      <td>-0.055719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data\\bbc\\business\\004.txt</th>\n",
       "      <td>-0.176339</td>\n",
       "      <td>-0.215292</td>\n",
       "      <td>0.215862</td>\n",
       "      <td>0.094050</td>\n",
       "      <td>0.498871</td>\n",
       "      <td>0.291168</td>\n",
       "      <td>-0.037569</td>\n",
       "      <td>0.238697</td>\n",
       "      <td>0.275630</td>\n",
       "      <td>0.069215</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.472698</td>\n",
       "      <td>0.062436</td>\n",
       "      <td>0.207713</td>\n",
       "      <td>0.127696</td>\n",
       "      <td>0.203626</td>\n",
       "      <td>-0.116648</td>\n",
       "      <td>0.153931</td>\n",
       "      <td>-0.271529</td>\n",
       "      <td>0.392614</td>\n",
       "      <td>0.046904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data\\bbc\\business\\005.txt</th>\n",
       "      <td>0.012977</td>\n",
       "      <td>-0.110308</td>\n",
       "      <td>0.362829</td>\n",
       "      <td>0.050718</td>\n",
       "      <td>0.246283</td>\n",
       "      <td>0.135647</td>\n",
       "      <td>0.093803</td>\n",
       "      <td>0.456370</td>\n",
       "      <td>-0.157749</td>\n",
       "      <td>0.013722</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.119206</td>\n",
       "      <td>0.116369</td>\n",
       "      <td>0.205224</td>\n",
       "      <td>0.263439</td>\n",
       "      <td>0.131355</td>\n",
       "      <td>-0.082300</td>\n",
       "      <td>0.016762</td>\n",
       "      <td>-0.227859</td>\n",
       "      <td>0.620660</td>\n",
       "      <td>0.082649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data\\bbc\\business\\006.txt</th>\n",
       "      <td>-0.217430</td>\n",
       "      <td>-0.267533</td>\n",
       "      <td>0.106997</td>\n",
       "      <td>0.060502</td>\n",
       "      <td>0.374277</td>\n",
       "      <td>-0.061184</td>\n",
       "      <td>-0.023888</td>\n",
       "      <td>0.141265</td>\n",
       "      <td>-0.199720</td>\n",
       "      <td>-0.235601</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.193753</td>\n",
       "      <td>0.035817</td>\n",
       "      <td>0.034229</td>\n",
       "      <td>0.325169</td>\n",
       "      <td>-0.046488</td>\n",
       "      <td>-0.058099</td>\n",
       "      <td>-0.135641</td>\n",
       "      <td>0.092746</td>\n",
       "      <td>0.592411</td>\n",
       "      <td>-0.077799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data\\bbc\\business\\007.txt</th>\n",
       "      <td>-0.095794</td>\n",
       "      <td>-0.428533</td>\n",
       "      <td>0.115057</td>\n",
       "      <td>0.008959</td>\n",
       "      <td>-0.070443</td>\n",
       "      <td>-0.069919</td>\n",
       "      <td>0.059792</td>\n",
       "      <td>0.243094</td>\n",
       "      <td>-0.314775</td>\n",
       "      <td>-0.171017</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.195365</td>\n",
       "      <td>0.023747</td>\n",
       "      <td>0.158869</td>\n",
       "      <td>0.291587</td>\n",
       "      <td>-0.130870</td>\n",
       "      <td>-0.005964</td>\n",
       "      <td>-0.090926</td>\n",
       "      <td>0.258044</td>\n",
       "      <td>0.587336</td>\n",
       "      <td>-0.145375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data\\bbc\\business\\008.txt</th>\n",
       "      <td>-0.151723</td>\n",
       "      <td>-0.386372</td>\n",
       "      <td>0.007322</td>\n",
       "      <td>-0.030916</td>\n",
       "      <td>0.108549</td>\n",
       "      <td>0.069729</td>\n",
       "      <td>-0.138714</td>\n",
       "      <td>0.425372</td>\n",
       "      <td>-0.271225</td>\n",
       "      <td>-0.164775</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.125985</td>\n",
       "      <td>0.087593</td>\n",
       "      <td>0.173060</td>\n",
       "      <td>0.119760</td>\n",
       "      <td>0.081384</td>\n",
       "      <td>-0.022957</td>\n",
       "      <td>-0.057328</td>\n",
       "      <td>0.061593</td>\n",
       "      <td>0.704508</td>\n",
       "      <td>-0.112707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data\\bbc\\business\\009.txt</th>\n",
       "      <td>-0.156948</td>\n",
       "      <td>-0.036727</td>\n",
       "      <td>0.205149</td>\n",
       "      <td>-0.459028</td>\n",
       "      <td>0.150166</td>\n",
       "      <td>0.178799</td>\n",
       "      <td>-0.100963</td>\n",
       "      <td>0.260349</td>\n",
       "      <td>0.145582</td>\n",
       "      <td>0.307759</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.077321</td>\n",
       "      <td>-0.125615</td>\n",
       "      <td>0.255359</td>\n",
       "      <td>0.340595</td>\n",
       "      <td>0.213240</td>\n",
       "      <td>0.062986</td>\n",
       "      <td>0.047997</td>\n",
       "      <td>-0.093237</td>\n",
       "      <td>0.320339</td>\n",
       "      <td>-0.013481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 1024 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               0         1         2         3         4     \\\n",
       "data\\bbc\\readme.txt        0.317657 -0.037904  0.096557 -0.120920 -0.031368   \n",
       "data\\bbc\\business\\001.txt  0.052209 -0.108837  0.103078  0.060255  0.277382   \n",
       "data\\bbc\\business\\002.txt -0.277251 -0.498861 -0.000488  0.090846  0.320750   \n",
       "data\\bbc\\business\\003.txt  0.001640 -0.078992  0.178254 -0.076050 -0.188926   \n",
       "data\\bbc\\business\\004.txt -0.176339 -0.215292  0.215862  0.094050  0.498871   \n",
       "data\\bbc\\business\\005.txt  0.012977 -0.110308  0.362829  0.050718  0.246283   \n",
       "data\\bbc\\business\\006.txt -0.217430 -0.267533  0.106997  0.060502  0.374277   \n",
       "data\\bbc\\business\\007.txt -0.095794 -0.428533  0.115057  0.008959 -0.070443   \n",
       "data\\bbc\\business\\008.txt -0.151723 -0.386372  0.007322 -0.030916  0.108549   \n",
       "data\\bbc\\business\\009.txt -0.156948 -0.036727  0.205149 -0.459028  0.150166   \n",
       "\n",
       "                               5         6         7         8         9     \\\n",
       "data\\bbc\\readme.txt        0.100202 -0.026247  0.396833 -0.147786 -0.080523   \n",
       "data\\bbc\\business\\001.txt  0.101622  0.147006  0.390242  0.053942 -0.051409   \n",
       "data\\bbc\\business\\002.txt -0.054692 -0.041421  0.329660 -0.438261 -0.232513   \n",
       "data\\bbc\\business\\003.txt  0.156753 -0.178013  0.316145  0.339274  0.103716   \n",
       "data\\bbc\\business\\004.txt  0.291168 -0.037569  0.238697  0.275630  0.069215   \n",
       "data\\bbc\\business\\005.txt  0.135647  0.093803  0.456370 -0.157749  0.013722   \n",
       "data\\bbc\\business\\006.txt -0.061184 -0.023888  0.141265 -0.199720 -0.235601   \n",
       "data\\bbc\\business\\007.txt -0.069919  0.059792  0.243094 -0.314775 -0.171017   \n",
       "data\\bbc\\business\\008.txt  0.069729 -0.138714  0.425372 -0.271225 -0.164775   \n",
       "data\\bbc\\business\\009.txt  0.178799 -0.100963  0.260349  0.145582  0.307759   \n",
       "\n",
       "                           ...      1014      1015      1016      1017  \\\n",
       "data\\bbc\\readme.txt        ... -0.287333  0.232494  0.078371  0.287477   \n",
       "data\\bbc\\business\\001.txt  ... -0.179657  0.053069  0.091880  0.257571   \n",
       "data\\bbc\\business\\002.txt  ... -0.140432 -0.022603  0.369779  0.214081   \n",
       "data\\bbc\\business\\003.txt  ...  0.077891  0.137827  0.199895 -0.000208   \n",
       "data\\bbc\\business\\004.txt  ... -0.472698  0.062436  0.207713  0.127696   \n",
       "data\\bbc\\business\\005.txt  ... -0.119206  0.116369  0.205224  0.263439   \n",
       "data\\bbc\\business\\006.txt  ... -0.193753  0.035817  0.034229  0.325169   \n",
       "data\\bbc\\business\\007.txt  ... -0.195365  0.023747  0.158869  0.291587   \n",
       "data\\bbc\\business\\008.txt  ... -0.125985  0.087593  0.173060  0.119760   \n",
       "data\\bbc\\business\\009.txt  ... -0.077321 -0.125615  0.255359  0.340595   \n",
       "\n",
       "                               1018      1019      1020      1021      1022  \\\n",
       "data\\bbc\\readme.txt        0.104193  0.087736  0.313276 -0.105956  0.213654   \n",
       "data\\bbc\\business\\001.txt  0.044403 -0.093912  0.032205 -0.116896  0.420686   \n",
       "data\\bbc\\business\\002.txt -0.019910 -0.004382 -0.073545  0.050382  0.697808   \n",
       "data\\bbc\\business\\003.txt  0.204819 -0.148592  0.030815 -0.008611  0.582661   \n",
       "data\\bbc\\business\\004.txt  0.203626 -0.116648  0.153931 -0.271529  0.392614   \n",
       "data\\bbc\\business\\005.txt  0.131355 -0.082300  0.016762 -0.227859  0.620660   \n",
       "data\\bbc\\business\\006.txt -0.046488 -0.058099 -0.135641  0.092746  0.592411   \n",
       "data\\bbc\\business\\007.txt -0.130870 -0.005964 -0.090926  0.258044  0.587336   \n",
       "data\\bbc\\business\\008.txt  0.081384 -0.022957 -0.057328  0.061593  0.704508   \n",
       "data\\bbc\\business\\009.txt  0.213240  0.062986  0.047997 -0.093237  0.320339   \n",
       "\n",
       "                               1023  \n",
       "data\\bbc\\readme.txt        0.086695  \n",
       "data\\bbc\\business\\001.txt  0.049002  \n",
       "data\\bbc\\business\\002.txt -0.038186  \n",
       "data\\bbc\\business\\003.txt -0.055719  \n",
       "data\\bbc\\business\\004.txt  0.046904  \n",
       "data\\bbc\\business\\005.txt  0.082649  \n",
       "data\\bbc\\business\\006.txt -0.077799  \n",
       "data\\bbc\\business\\007.txt -0.145375  \n",
       "data\\bbc\\business\\008.txt -0.112707  \n",
       "data\\bbc\\business\\009.txt -0.013481  \n",
       "\n",
       "[10 rows x 1024 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elmo_doc_embeddings = pd.read_pickle(\n",
    "    os.path.join('elmo_embeddings', 'elmo_embeddings.pkl')\n",
    ")\n",
    "\n",
    "elmo_doc_embeddings.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e02751f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    0         1         2         3     \\\n",
      "data\\bbc\\entertainment\\248.txt  0.138944 -0.041703  0.048184 -0.070518   \n",
      "data\\bbc\\entertainment\\079.txt -0.072277  0.023420 -0.105915 -0.103559   \n",
      "data\\bbc\\business\\202.txt       0.071975 -0.063900  0.136218  0.046118   \n",
      "data\\bbc\\politics\\068.txt      -0.129725  0.070762  0.056560 -0.149941   \n",
      "data\\bbc\\sport\\136.txt         -0.252077 -0.341544 -0.133118 -0.086479   \n",
      "...                                  ...       ...       ...       ...   \n",
      "data\\bbc\\entertainment\\201.txt  0.088658 -0.286841 -0.022951 -0.114855   \n",
      "data\\bbc\\tech\\036.txt          -0.122197 -0.062747 -0.096102  0.060893   \n",
      "data\\bbc\\entertainment\\153.txt -0.094684 -0.166768 -0.079259  0.048055   \n",
      "data\\bbc\\tech\\137.txt          -0.080943 -0.056395  0.107801 -0.128051   \n",
      "data\\bbc\\entertainment\\310.txt  0.229003 -0.137286 -0.143722 -0.092213   \n",
      "\n",
      "                                    4         5         6         7     \\\n",
      "data\\bbc\\entertainment\\248.txt  0.108707  0.420036 -0.132674  0.033153   \n",
      "data\\bbc\\entertainment\\079.txt  0.104401  0.127100 -0.009825  0.249125   \n",
      "data\\bbc\\business\\202.txt       0.184408  0.032695  0.065789  0.432480   \n",
      "data\\bbc\\politics\\068.txt       0.201815  0.047514  0.050885  0.254708   \n",
      "data\\bbc\\sport\\136.txt          0.086758  0.403073 -0.110678  0.279645   \n",
      "...                                  ...       ...       ...       ...   \n",
      "data\\bbc\\entertainment\\201.txt  0.408141  0.539494  0.033329  0.211180   \n",
      "data\\bbc\\tech\\036.txt           0.222382 -0.240121 -0.060824 -0.258736   \n",
      "data\\bbc\\entertainment\\153.txt  0.208585  0.444669 -0.159232  0.134644   \n",
      "data\\bbc\\tech\\137.txt           0.296070  0.083854  0.003235  0.104676   \n",
      "data\\bbc\\entertainment\\310.txt  0.284417  0.474810  0.219111  0.193247   \n",
      "\n",
      "                                    8         9     ...      1014      1015  \\\n",
      "data\\bbc\\entertainment\\248.txt  0.245747  0.045663  ... -0.122735 -0.046004   \n",
      "data\\bbc\\entertainment\\079.txt  0.391078 -0.160653  ... -0.089221  0.338690   \n",
      "data\\bbc\\business\\202.txt       0.063723  0.109673  ... -0.080189  0.053792   \n",
      "data\\bbc\\politics\\068.txt      -0.159586  0.044758  ... -0.058503  0.191729   \n",
      "data\\bbc\\sport\\136.txt          0.069235  0.165004  ...  0.062589  0.140037   \n",
      "...                                  ...       ...  ...       ...       ...   \n",
      "data\\bbc\\entertainment\\201.txt  0.009021 -0.290460  ... -0.346214  0.328216   \n",
      "data\\bbc\\tech\\036.txt          -0.373172  0.097595  ... -0.384590  0.054648   \n",
      "data\\bbc\\entertainment\\153.txt -0.015769 -0.253936  ... -0.319807  0.144258   \n",
      "data\\bbc\\tech\\137.txt          -0.286749  0.075121  ... -0.123870  0.252026   \n",
      "data\\bbc\\entertainment\\310.txt  0.231295 -0.169951  ... -0.168773  0.251401   \n",
      "\n",
      "                                    1016      1017      1018      1019  \\\n",
      "data\\bbc\\entertainment\\248.txt  0.350949  0.066046 -0.051945  0.116656   \n",
      "data\\bbc\\entertainment\\079.txt -0.071375  0.170496 -0.036472 -0.099211   \n",
      "data\\bbc\\business\\202.txt      -0.119412  0.205002  0.129243  0.218515   \n",
      "data\\bbc\\politics\\068.txt       0.031812 -0.005115 -0.055651  0.066149   \n",
      "data\\bbc\\sport\\136.txt          0.064825 -0.012532  0.115969 -0.201115   \n",
      "...                                  ...       ...       ...       ...   \n",
      "data\\bbc\\entertainment\\201.txt -0.063852  0.014207 -0.064896 -0.134128   \n",
      "data\\bbc\\tech\\036.txt           0.113181  0.282817 -0.143428 -0.091932   \n",
      "data\\bbc\\entertainment\\153.txt  0.113425 -0.019296  0.003491 -0.058682   \n",
      "data\\bbc\\tech\\137.txt          -0.123512  0.332126  0.217875  0.111069   \n",
      "data\\bbc\\entertainment\\310.txt -0.084615  0.181708 -0.027307  0.058769   \n",
      "\n",
      "                                    1020      1021      1022      1023  \n",
      "data\\bbc\\entertainment\\248.txt -0.000526 -0.032500  0.357812  0.037024  \n",
      "data\\bbc\\entertainment\\079.txt  0.043518 -0.054138  0.331612 -0.029316  \n",
      "data\\bbc\\business\\202.txt       0.077617  0.031661  0.483388  0.019613  \n",
      "data\\bbc\\politics\\068.txt       0.393417 -0.058311  0.338814 -0.013695  \n",
      "data\\bbc\\sport\\136.txt          0.148682 -0.051474  0.483647  0.006301  \n",
      "...                                  ...       ...       ...       ...  \n",
      "data\\bbc\\entertainment\\201.txt -0.076578 -0.062869  0.388767  0.168547  \n",
      "data\\bbc\\tech\\036.txt           0.057022 -0.182448  0.131668 -0.245529  \n",
      "data\\bbc\\entertainment\\153.txt -0.055727 -0.037347  0.517247  0.091443  \n",
      "data\\bbc\\tech\\137.txt           0.486801  0.059476  0.588761 -0.104437  \n",
      "data\\bbc\\entertainment\\310.txt  0.029839 -0.052618  0.452387  0.040350  \n",
      "\n",
      "[1490 rows x 1024 columns]\n",
      "data\\bbc\\entertainment\\248.txt    1\n",
      "data\\bbc\\entertainment\\079.txt    1\n",
      "data\\bbc\\business\\202.txt         0\n",
      "data\\bbc\\politics\\068.txt         2\n",
      "data\\bbc\\sport\\136.txt            3\n",
      "                                 ..\n",
      "data\\bbc\\entertainment\\201.txt    1\n",
      "data\\bbc\\tech\\036.txt             4\n",
      "data\\bbc\\entertainment\\153.txt    1\n",
      "data\\bbc\\tech\\137.txt             4\n",
      "data\\bbc\\entertainment\\310.txt    1\n",
      "Name: 2, Length: 1490, dtype: int32\n",
      "[0.9768707482993197, 0.9768707482993197, 0.9768707482993197, 0.9768707482993197, 0.9768707482993197]\n"
     ]
    }
   ],
   "source": [
    "elmo_accuracies = get_classification_accuracy(\n",
    "    elmo_doc_embeddings, train_labels, test_labels, n_trials=5\n",
    ")\n",
    "print(elmo_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06df915",
   "metadata": {},
   "source": [
    "## Plot the accuracies of different models\n",
    "\n",
    "Here we plot the accuracies from 5 trials, for different algorithms as box plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7c3f2383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Skipgram</th>\n",
       "      <th>CBOW</th>\n",
       "      <th>GloVe</th>\n",
       "      <th>ELMo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.851701</td>\n",
       "      <td>0.801361</td>\n",
       "      <td>0.663946</td>\n",
       "      <td>0.976871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.851701</td>\n",
       "      <td>0.801361</td>\n",
       "      <td>0.663946</td>\n",
       "      <td>0.976871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.851701</td>\n",
       "      <td>0.801361</td>\n",
       "      <td>0.663946</td>\n",
       "      <td>0.976871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.851701</td>\n",
       "      <td>0.801361</td>\n",
       "      <td>0.663946</td>\n",
       "      <td>0.976871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.851701</td>\n",
       "      <td>0.801361</td>\n",
       "      <td>0.663946</td>\n",
       "      <td>0.976871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Skipgram      CBOW     GloVe      ELMo\n",
       "0  0.851701  0.801361  0.663946  0.976871\n",
       "1  0.851701  0.801361  0.663946  0.976871\n",
       "2  0.851701  0.801361  0.663946  0.976871\n",
       "3  0.851701  0.801361  0.663946  0.976871\n",
       "4  0.851701  0.801361  0.663946  0.976871"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_df = pd.DataFrame(\n",
    "    np.array([skipgram_accuracies, cbow_accuracies, glove_accuracies, elmo_accuracies]).T,\n",
    "    columns = ['Skipgram', 'CBOW', \"GloVe\", \"ELMo\"]\n",
    ")\n",
    "\n",
    "accuracy_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6499c821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "boxplot = accuracy_df.boxplot(figsize=(10,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea8a1cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
